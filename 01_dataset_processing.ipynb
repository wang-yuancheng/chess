{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a556080-2188-45bf-90de-44c12b252e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict, Iterator, Optional, Any, Generator, Tuple\n",
    "from enum import Enum\n",
    "import sys, asyncio\n",
    "import chess\n",
    "import chess.pgn\n",
    "import chess.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9204531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Stockfish executable: stockfish\\stockfish-windows-x86-64-avx2.exe\n"
     ]
    }
   ],
   "source": [
    "if sys.platform.startswith(\"win\"):\n",
    "    stockfish_executable_path = Path(\"./stockfish/stockfish-windows-x86-64-avx2.exe\")\n",
    "    print(f\"Using Stockfish executable: {stockfish_executable_path}\")\n",
    "\n",
    "if sys.platform.startswith(\"darwin\"):\n",
    "    stockfish_executable_path = Path(\"./stockfish/stockfish-macos-m1-apple-silicon\")\n",
    "    print(f\"Using Stockfish executable: {stockfish_executable_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b96090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_games(pgn_path: Path) -> Iterator[chess.pgn.Game]:\n",
    "    \"\"\"Yield games one by one from a PGN file\"\"\"\n",
    "    \n",
    "    if pgn_path.suffix.lower() != \".pgn\":\n",
    "        raise ValueError(f\"Expected a .pgn file, got: {pgn_path.suffix}\")\n",
    "    \n",
    "    with open(pgn_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "            yield game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27535a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Policy: WindowsSelectorEventLoopPolicy\n",
      "New Policy: WindowsProactorEventLoopPolicy\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Why this cell exists:\n",
    "- python-chess launches Stockfish via asyncio.subprocess_exec.\n",
    "- On Windows, the Selector event loop cannot create subprocesses, it raises NotImplementedError.\n",
    "- Some Jupyter kernels on Windows start with the Selector policy by default.\n",
    "- Switching to WindowsProactorEventLoopPolicy enables subprocess support in this notebook.\n",
    "\n",
    "How to use:\n",
    "- Run this cell once before creating the engine.\n",
    "- On macOS or Linux this does nothing and is safe.\n",
    "\"\"\"\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    print(f\"Initial Policy: {type(asyncio.get_event_loop_policy()).__name__}\")\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "    print(f\"New Policy: {type(asyncio.get_event_loop_policy()).__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09fa9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionLabel(Enum):\n",
    "    WHITE_WINNING = 0\n",
    "    WHITE_DECISIVE = 1\n",
    "    WHITE_BETTER = 2\n",
    "    EQUAL = 3\n",
    "    BLACK_BETTER = 4\n",
    "    BLACK_DECISIVE = 5\n",
    "    BLACK_WINNING = 6\n",
    "\n",
    "class GameStage(Enum):\n",
    "    OPENING = 0\n",
    "    MIDDLEGAME = 1\n",
    "    ENDGAME = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7897121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_result(game: chess.pgn.Game) -> float | None:\n",
    "    \"\"\"\n",
    "    Parses the PGN header result into a float.\n",
    "    Returns None if the game is unfinished or unknown ('*').\n",
    "    \"\"\"\n",
    "    res = game.headers.get(\"Result\", \"*\")\n",
    "    if res == \"1-0\":\n",
    "        return 1.0\n",
    "    elif res == \"0-1\":\n",
    "        return 0.0\n",
    "    elif res == \"1/2-1/2\":\n",
    "        return 0.5\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tapered_phase_score(board: chess.Board) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the game phase based on Non-Pawn Material (NPM).\n",
    "    Returns a phase factor 'p' where:\n",
    "    - 1.0 represents the Start of the game (Opening/Middlegame).\n",
    "    - 0.0 represents a completely empty board (Pure Endgame).\n",
    "    \n",
    "    Credits: Stockfish\n",
    "    \"\"\"\n",
    "    \n",
    "    phase = 0\n",
    "    MAX_PHASE = 24\n",
    "    phase_weights = {\n",
    "        chess.KNIGHT: 1,\n",
    "        chess.BISHOP: 1,\n",
    "        chess.ROOK: 2,\n",
    "        chess.QUEEN: 4\n",
    "    }\n",
    "\n",
    "    for piece_type, weight in phase_weights.items():\n",
    "        count = len(board.pieces(piece_type, chess.WHITE)) + \\\n",
    "                len(board.pieces(piece_type, chess.BLACK))\n",
    "        phase += count * weight\n",
    "    \n",
    "    # Clamp phase to ensure it never exceeds bounds (e.g. unexpected promotions)\n",
    "    phase = min(phase, MAX_PHASE)\n",
    "    \n",
    "    # Normalize (0.0 to 1.0)\n",
    "    return phase / MAX_PHASE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eed1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def process_game(game: chess.pgn.Game) -> Generator[Dict[str, Any], None, None]:\n",
    "    \"\"\"\n",
    "    Iterates through a single game and yields a dictionary for every position.\n",
    "    Skip the game if result is unknown.\n",
    "    \"\"\"\n",
    "    result = get_game_result(game)\n",
    "    if result is None:\n",
    "        return  \n",
    "    \n",
    "    board = game.board()\n",
    "    \n",
    "    for move in game.mainline_moves():\n",
    "        try:\n",
    "            board.push(move)\n",
    "            board_copy = board.copy()\n",
    "            legal_moves = list(board_copy.legal_moves)\n",
    "\n",
    "            if legal_moves:\n",
    "                # 3. Apply ONE random legal move (includes captures, checks, etc.)\n",
    "                random_move = random.choice(legal_moves)\n",
    "                board_copy.push(random_move)\n",
    "                \n",
    "                # 4. Calculate stats for this new, fictitious position\n",
    "                aug_fen = board_copy.fen()\n",
    "                aug_phase = get_tapered_phase_score(board_copy)\n",
    "                \n",
    "                if aug_phase > 0.66:\n",
    "                    aug_stage = 0 # Opening\n",
    "                elif aug_phase > 0.15: \n",
    "                    aug_stage = 1 # Middlegame\n",
    "                else:\n",
    "                    aug_stage = 2 # Endgame\n",
    "\n",
    "                aug_check = board_copy.is_check()\n",
    "                \n",
    "                yield {\n",
    "                    \"fen\": aug_fen,\n",
    "                    \"game_result\": result, # Kept for schema compatibility, but unreliable now\n",
    "                    \"game_phase\": aug_phase,\n",
    "                    \"game_stage\": aug_stage,\n",
    "                    \"is_check\": aug_check\n",
    "                }\n",
    "\n",
    "        except ValueError:\n",
    "            continue # Skip illegal moves if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89e5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_evaluator(fen_batch: List[str]) -> List[Tuple[Optional[int], Optional[int]]]:\n",
    "    \"\"\"\n",
    "    Worker function: Starts Stockfish, processes a list of FENs, returns scores then quits.\n",
    "    \"\"\"\n",
    "\n",
    "    if sys.platform.startswith(\"win\"):\n",
    "        engine_path = Path(\"./stockfish/stockfish-windows-x86-64-avx2.exe\")\n",
    "    else:\n",
    "        engine_path = Path(\"./stockfish/stockfish-macos-m1-apple-silicon\")\n",
    "        \n",
    "    results = []\n",
    "    engine = None\n",
    "    \n",
    "    try:\n",
    "        engine = chess.engine.SimpleEngine.popen_uci(str(engine_path))\n",
    "                \n",
    "        for fen in fen_batch:\n",
    "            board = chess.Board(fen)\n",
    "            \n",
    "            # Depth 10 (Impulsive)\n",
    "            info_depth_10 = engine.analyse(board, chess.engine.Limit(depth=10))\n",
    "            score_depth_10 = info_depth_10[\"score\"].white().score(mate_score=10000)\n",
    "            \n",
    "            # Depth 20 (Truth)\n",
    "            info_depth_20 = engine.analyse(board, chess.engine.Limit(depth=20))\n",
    "            score_depth_20 = info_depth_20[\"score\"].white().score(mate_score=10000)\n",
    "            \n",
    "            results.append((score_depth_10, score_depth_20))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Worker Error: {e}\")\n",
    "        results = [(None, None)] * len(fen_batch)\n",
    "        \n",
    "    finally:\n",
    "        if engine:\n",
    "            engine.quit()\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0313def2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ryzen 5900X 12 Core\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce3941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_label(cp: float) -> int:\n",
    "    \"\"\"\n",
    "    Classifies centipawn score into an integer label (0-6).\n",
    "    \n",
    "    0: White Winning (>= 500)\n",
    "    1: White Decisive (300 to 499)\n",
    "    2: White Better   (100 to 299)\n",
    "    3: Equal          (-99 to 99)\n",
    "    4: Black Better   (-100 to -299)\n",
    "    5: Black Decisive (-300 to -499)\n",
    "    6: Black Winning  (<= -500)\n",
    "    \"\"\"\n",
    "    if cp >= 500:       return 0\n",
    "    if 500 > cp >= 300: return 1\n",
    "    if 300 > cp >= 100: return 2\n",
    "    if 100 > cp > -100: return 3\n",
    "    if -100 >= cp > -300: return 4\n",
    "    if -300 > cp >= -500: return 5\n",
    "    return 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f296ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import tqdm\n",
    "\n",
    "def run_parallel_evaluation(position_dataset: List[Dict], chunk_size: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Splits data into chunks, runs parallel evaluation.\n",
    "    Uses a 'temporary' progress bar that vanishes when done.\n",
    "    \"\"\"\n",
    "    num_workers = 10\n",
    "\n",
    "    fens = [d[\"fen\"] for d in position_dataset]    \n",
    "    chunks = [fens[i:i + chunk_size] for i in range(0, len(fens), chunk_size)]\n",
    "    \n",
    "    flat_results = []\n",
    "    \n",
    "    # ThreadPoolExecutor yields values in the exact same order as the inputs were passed\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        all_batch_results = tqdm(executor.map(worker_evaluator, chunks), \n",
    "                                 total=len(chunks), \n",
    "                                 desc=\"Stockfish Eval\", \n",
    "                                 unit=\"chunk\",\n",
    "                                 leave=False) \n",
    "        \n",
    "        for batch_result in all_batch_results:\n",
    "            flat_results.extend(batch_result)\n",
    "\n",
    "    # Merge Scores into Metadata\n",
    "    labeled_data = []\n",
    "    \n",
    "    for i, scores in enumerate(flat_results):\n",
    "        if scores is not None:\n",
    "            row = position_dataset[i]\n",
    "\n",
    "            score_10 = float(scores[0])\n",
    "            score_20 = float(scores[1])\n",
    "            row[\"stockfish_score_depth_10\"] = score_10\n",
    "            row[\"stockfish_score_depth_20\"] = score_20\n",
    "            row[\"stockfish_label_depth_20\"] = get_score_label(score_20)\n",
    "            labeled_data.append(row)\n",
    "            \n",
    "    return labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b439e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def get_next_batch_index(existing_parts) -> int:\n",
    "    indices = []\n",
    "    for f in existing_parts:\n",
    "        try:\n",
    "            indices.append(int(f.stem.split(\"_\")[-1]))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return (max(indices) + 1) if indices else 0\n",
    "\n",
    "def make_save_path(output_dir: Path, batch_index: int) -> Path:\n",
    "    return output_dir / f\"data_part_{batch_index:04d}.parquet\"\n",
    "\n",
    "def evaluate_and_save_batch(batch, output_dir: Path, batch_index: int, chunk_size:int ) -> int:\n",
    "    evaluated_batch = run_parallel_evaluation(batch, chunk_size)\n",
    "    df = pd.DataFrame(evaluated_batch)\n",
    "    df.to_parquet(make_save_path(output_dir, batch_index), index=False)\n",
    "\n",
    "    # cleanup\n",
    "    del evaluated_batch, df\n",
    "    gc.collect()\n",
    "\n",
    "    return batch_index + 1\n",
    "\n",
    "def run_batch_pipeline(pgn_folder: Path, target_count: int, batch_size: int, output_dir: Path, chunk_size:int):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    seen_fens = set()\n",
    "    current_batch = []\n",
    "\n",
    "    existing_parts = list(output_dir.glob(\"data_part_*.parquet\"))\n",
    "\n",
    "    # Resume\n",
    "    if existing_parts:\n",
    "        print(f\"Found {len(existing_parts)} existing parts. Loading seen FENs to resume...\")\n",
    "        for file_path in tqdm(existing_parts, desc=\"Resuming\"):\n",
    "            try:\n",
    "                df_existing = pd.read_parquet(file_path, columns=[\"fen\"])\n",
    "                seen_fens.update(df_existing[\"fen\"].tolist())\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read {file_path}: {e}\")\n",
    "\n",
    "    batch_index = get_next_batch_index(existing_parts)\n",
    "    total_collected = len(seen_fens)\n",
    "\n",
    "    print(f\"Resumed with {total_collected} positions. Next Batch Index: {batch_index}\")\n",
    "    print(f\"Starting pipeline. Target: {target_count} | Batch Size: {batch_size}\")\n",
    "\n",
    "    pgn_files = list(pgn_folder.glob(\"*.pgn\"))\n",
    "    if not pgn_files:\n",
    "        print(\"No PGN files found!\")\n",
    "        return\n",
    "\n",
    "    pbar = tqdm(total=target_count, initial=total_collected, desc=\"Total Progress\", unit=\"pos\")\n",
    "\n",
    "    for pgn_file in pgn_files:\n",
    "        if total_collected >= target_count:\n",
    "            break\n",
    "\n",
    "        for game in iter_games(pgn_file):\n",
    "            if total_collected >= target_count:\n",
    "                break\n",
    "\n",
    "            for position in process_game(game):\n",
    "                fen = position[\"fen\"]\n",
    "\n",
    "                if fen in seen_fens:\n",
    "                    continue\n",
    "\n",
    "                seen_fens.add(fen)\n",
    "                current_batch.append(position)\n",
    "                total_collected += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "                if len(current_batch) >= batch_size:\n",
    "                    batch_index = evaluate_and_save_batch(current_batch, output_dir, batch_index, chunk_size)\n",
    "                    current_batch.clear()\n",
    "\n",
    "                if total_collected >= target_count:\n",
    "                    break\n",
    "\n",
    "    # Final partial batch\n",
    "    if current_batch:\n",
    "        print(f\"Processing final partial batch of {len(current_batch)}...\")\n",
    "        batch_index = evaluate_and_save_batch(current_batch, output_dir, batch_index, chunk_size)\n",
    "        print(f\"Saved final batch {batch_index - 1}\")\n",
    "\n",
    "    pbar.close()\n",
    "    print(\"Run Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ee491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 existing parts. Loading seen FENs to resume...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resuming: 100%|██████████| 100/100 [00:00<00:00, 128.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed with 1000000 positions. Next Batch Index: 100\n",
      "Starting pipeline. Target: 5000000 | Batch Size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  85%|████████▌ | 4270000/5000000 [58:40:03<03:59, 3050.20pos/s]   "
     ]
    }
   ],
   "source": [
    "TARGET_POSITIONS = 5000000   \n",
    "BATCH_SIZE = 10000           # Saves 1 file every 10k positions (100 files total)\n",
    "CHUNK_SIZE = 250             # 10,000 / 250 = 40 tasks. Perfect for 12 workers.    \n",
    "\n",
    "GAMES_FOLDER = Path(\"./cclr/train\")\n",
    "OUTPUT_DIR = Path(\"./dataset_parts\")\n",
    "\n",
    "run_batch_pipeline(GAMES_FOLDER, TARGET_POSITIONS, BATCH_SIZE, OUTPUT_DIR, CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063c8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessenv",
   "language": "python",
   "name": "chessenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
