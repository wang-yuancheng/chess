{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b389472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import chess\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ed291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.9\n",
      "GPU: NVIDIA GeForce RTX 3070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU:\", torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff0e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"run_2026_01_17_probs_seresnet_droppath_c64_v10\"\n",
    "model_save_name = \"probs_seresnet_droppath_c64_v10\"\n",
    "# bn is bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39910bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPZChessDataset(Dataset):\n",
    "    def __init__(self, npz_path: Path, sigma: float = 0.6):\n",
    "        with np.load(npz_path) as data:\n",
    "            self.X = torch.tensor(data[\"X\"], dtype=torch.float32) # float32 for NNs\n",
    "            self.y = torch.tensor(data[\"y\"], dtype=torch.long) # long for CrossEntropyLoss\n",
    "            self.scores = torch.tensor(data[\"scores\"], dtype=torch.float32)\n",
    "            self.num_classes = 7\n",
    "            self.sigma = sigma\n",
    "            self.class_indices = torch.arange(self.num_classes, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def score_to_continuous_index(self, score: float) -> float:\n",
    "        \"\"\"\n",
    "        Maps Centipawn score to a continuous index (e.g. 400cp -> 1.5).\n",
    "        \"\"\"\n",
    "        \n",
    "        if score >= 500: \n",
    "            # Fade from 0.5 (at 500) to 0.0 (at 700)\n",
    "            return max(0.0, 0.5 - (score - 500) / 200.0)\n",
    "        \n",
    "        if score <= -500:\n",
    "            # Fade from 5.5 (at -500) to 6.0 (at -700)\n",
    "            return min(6.0, 5.5 + (-500 - score) / 200.0)\n",
    "        \n",
    "        # Interpolate the Middle Classes\n",
    "        # 300 to 500  -> Maps to 1.5 to 0.5\n",
    "        if score >= 300: return 1.5 - (score - 300) / 200.0\n",
    "        # 100 to 300  -> Maps to 2.5 to 1.5\n",
    "        if score >= 100: return 2.5 - (score - 100) / 200.0\n",
    "        # -100 to 100 -> Maps to 3.5 to 2.5\n",
    "        if score >= -100: return 3.5 - (score - (-100)) / 200.0\n",
    "        # -300 to -100 -> Maps to 4.5 to 3.5\n",
    "        if score >= -300: return 4.5 - (score - (-300)) / 200.0\n",
    "        # -500 to -300 -> Maps to 5.5 to 4.5\n",
    "        if score > -500: return 5.5 - (score - (-500)) / 200.0\n",
    "        \n",
    "        return 3.0 \n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        score = self.scores[idx].item()\n",
    "        target_idx = self.score_to_continuous_index(score)\n",
    "        \n",
    "        # Create Gaussian Distribution centered at target_idx\n",
    "        dist = torch.exp(-((self.class_indices - target_idx) ** 2) / (2 * self.sigma ** 2))\n",
    "        \n",
    "        # Normalize so it sums to 1.0\n",
    "        soft_target = dist / dist.sum()\n",
    "\n",
    "        # return self.X[idx], self.y[idx]\n",
    "        return self.X[idx], soft_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15af8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "num_workers = 0\n",
    "\n",
    "TRAIN_PATH = Path(\"./dataset_planes_cp/plane_train.npz\")\n",
    "VAL_PATH = Path(\"./dataset_planes_cp/plane_val.npz\")\n",
    "TEST_PATH = Path(\"./dataset_planes_cp/plane_test.npz\") \n",
    "\n",
    "train_dataloader = DataLoader(dataset=NPZChessDataset(TRAIN_PATH), \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True)\n",
    "val_dataloader = DataLoader(dataset=NPZChessDataset(VAL_PATH), \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            num_workers=num_workers,\n",
    "                            shuffle=False,\n",
    "                            pin_memory=True)\n",
    "test_dataloader = DataLoader(dataset=NPZChessDataset(TEST_PATH), \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                          num_workers=num_workers,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afc6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg batch load time: 0.041175272464752194\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for i, (X, y) in enumerate(train_dataloader):\n",
    "    if i == 100:  # measure 100 batches\n",
    "        break\n",
    "print(\"Avg batch load time:\", (time.time() - start) / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5bdf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch shape: torch.Size([512, 19, 8, 8]) dtype: torch.float32\n",
      "y batch shape: torch.Size([512, 7]) dtype: torch.float32 classes in batch: [1.5390388484403716e-22, 1.8077143966858269e-22, 1.8077145229035717e-22, 2.1230019056634916e-22, 2.30059456405017e-22, 2.4929496498727927e-22, 3.4360403089114576e-22, 3.722665661303184e-22, 4.369208991028615e-22, 6.016000180670424e-22, 1.334754873066261e-21, 1.334754974040457e-21, 1.8337917653188306e-21, 1.9851353232088824e-21, 2.517711804361063e-21, 3.454282004214435e-21, 4.04498347342463e-21, 4.376932103373797e-21, 7.018715547011237e-21, 8.212169149863331e-21, 1.1235834174997158e-20, 1.2150409973558108e-20, 1.2150410781351675e-20, 1.3138742979336224e-20, 1.536081344535648e-20, 2.4517281158076552e-20, 2.4517282773663686e-20, 2.6499246295431953e-20, 2.86404049266126e-20, 3.095261384559413e-20, 3.6146500298860195e-20, 3.905876089758932e-20, 4.2203262146815514e-20, 5.32215728623118e-20, 5.322157609348607e-20, 5.749384763504882e-20, 6.708419258168569e-20, 7.825639766520805e-20, 9.855741322530538e-20, 1.3393901056444984e-19, 1.684862734712124e-19, 2.1183277354158436e-19, 2.1183278646628143e-19, 2.6619150325748063e-19, 2.872175813985719e-19, 3.343236561270886e-19, 4.52660166257713e-19, 4.882090802627919e-19, 5.678067577536032e-19, 6.122915488197277e-19, 6.60217101041343e-19, 6.602171527401313e-19, 7.118566942133214e-19, 7.674862964675259e-19, 8.9196270979119e-19, 9.614931339381364e-19, 1.036380896719859e-18, 1.2038760785702622e-18, 1.2974054938292097e-18, 1.3981107009020546e-18, 1.6232614054231695e-18, 1.6232738131323578e-18, 1.8842148649998405e-18, 2.0298375302979633e-18, 2.1865634409583855e-18, 2.3552625841903596e-18, 2.53681032387712e-18, 2.732183146731785e-18, 2.942419784808569e-18, 3.168613150491807e-18, 3.4119949157135905e-18, 3.955521854537231e-18, 4.258549132188376e-18, 4.935079475680183e-18, 5.3121311463486985e-18, 6.153651348410639e-18, 7.126740830753733e-18, 7.668741000961754e-18, 8.251501323033938e-18, 9.55139911204877e-18, 1.105319349061432e-17, 1.7103598636507927e-17, 1.9772452215157193e-17, 2.1257292699887856e-17, 2.2852014202828838e-17, 2.456498613741795e-17, 3.522406032619464e-17, 4.369410193988448e-17, 5.4168369090565796e-17, 6.249184753460104e-17, 7.207497977648918e-17, 1.0284861319252397e-16, 1.0284861980996887e-16, 1.104067675902129e-16, 1.272055816038583e-16, 1.365272718326205e-16, 1.8104446480410953e-16, 1.8104447803899933e-16, 2.57250152949117e-16, 2.759188385159406e-16, 3.173607460235249e-16, 3.9128692292368325e-16, 4.497625835912127e-16, 4.497626365307719e-16, 5.168347287008669e-16, 5.539810939049082e-16, 5.937586610804766e-16, 6.642061266058207e-16, 6.819459611366412e-16, 7.307657638428269e-16, 7.587883665950777e-16, 7.587884724741961e-16, 8.389695112337946e-16, 8.667133872068396e-16, 9.262603857339681e-16, 9.629462297124991e-16, 9.898653602927144e-16, 1.1049492916164329e-15, 1.183494868573561e-15, 1.2675454185340131e-15, 1.2906031376659329e-15, 1.3574810475328698e-15, 1.3789751438441581e-15, 1.4536966846817882e-15, 1.5741379935177717e-15, 1.6667273767403761e-15, 1.9104726481367074e-15, 2.0451923913645566e-15, 2.050310164431867e-15, 2.1892756603078285e-15, 2.508101190994952e-15, 2.684232163255827e-15, 2.872562951056006e-15, 3.2891362956145127e-15, 3.765074156039574e-15, 3.959111193047168e-15, 3.959111616563642e-15, 4.0278830685841656e-15, 4.60887228446831e-15, 4.929553029068157e-15, 5.145366436116712e-15, 5.2722134316163065e-15, 5.493186539863061e-15, 5.638315047463245e-15, 6.0294342049238125e-15, 6.447202289454421e-15, 6.682578769452762e-15, 8.422928661781705e-15, 8.672999892865487e-15, 9.003521466246535e-15, 9.877946611982092e-15, 1.054110225891464e-14, 1.2551950005366876e-14, 1.530849083023096e-14, 1.5551802738395654e-14, 1.635360243220068e-14, 1.7468836503741793e-14, 1.7697769180593896e-14, 1.9928504986087454e-14, 2.290548020624384e-14, 2.4269813115045287e-14, 2.4428237075302048e-14, 2.4428238769367942e-14, 2.605096585499289e-14, 2.766803814866197e-14, 2.953863417970784e-14, 2.953863756783963e-14, 2.962233797555551e-14, 3.592845083401873e-14, 4.349965822118308e-14, 4.349966160931487e-14, 4.367334063295168e-14, 4.367334402108347e-14, 4.6367911680361695e-14, 4.660321404497715e-14, 4.942293929254167e-14, 5.2676538532612366e-14, 5.660205174029022e-14, 5.983030775457907e-14, 6.375897531295249e-14, 6.79419086095645e-14, 8.21833988124028e-14, 8.218340558866638e-14, 8.33365833481127e-14, 8.755611524430967e-14, 9.475338130218378e-14, 9.936201980555864e-14, 1.0102411528850608e-13, 1.1273426446913384e-13, 1.1481558705086353e-13, 1.223884546226045e-13, 1.3045219472793829e-13, 1.361852525281343e-13, 1.5790670095279513e-13, 1.7507418854489226e-13, 1.9101677162756958e-13, 2.1124313236142722e-13, 2.547510000259351e-13, 2.547510271309894e-13, 2.6196525417659933e-13, 3.070588488335302e-13, 3.1635623482829944e-13, 3.2674367768728563e-13, 3.368420722470872e-13, 3.586272988645445e-13, 3.6991194612631673e-13, 3.8179547956311566e-13, 4.064333776216539e-13, 4.73779381612166e-13, 5.039377118723487e-13, 5.215657549947905e-13, 5.215658092048991e-13, 5.550264566521468e-13, 5.700449335656332e-13, 5.905900768432559e-13, 6.062263321546246e-13, 6.446620039006479e-13, 6.446620581107565e-13, 6.685550008565799e-13, 6.854973945251419e-13, 7.288729082094436e-13, 8.238812735338052e-13, 8.758546188661342e-13, 9.103929632728325e-13, 9.31050375685416e-13, 1.051892730905002e-12, 1.1179761543606004e-12, 1.1639860082734987e-12, 1.1881365032453961e-12, 1.3416855517214832e-12, 1.341693357977125e-12, 1.4865357209070673e-12, 1.5147099069814929e-12, 1.6092677320930782e-12, 1.7096098842150909e-12, 1.816106726809652e-12, 1.8963199066579506e-12, 1.9291181065778096e-12, 2.04903151737601e-12, 2.140903556865914e-12, 2.176263075998053e-12, 2.3112338865677318e-12, 2.454441381041783e-12, 2.5668083110386153e-12, 2.767476569090488e-12, 2.938386730114151e-12, 3.0754975389318817e-12, 3.311907388961477e-12, 3.515772308698706e-12, 3.961159959070537e-12, 4.461839318153915e-12, 4.678065226859651e-12, 4.7349632895099525e-12, 4.9655535759585145e-12, 5.024516393226097e-12, 5.270325408729404e-12, 5.656724654662382e-12, 5.9358837289913424e-12, 6.366807688701348e-12, 6.683634982268538e-12, 7.523481837523605e-12, 9.064192972585428e-12, 9.525160174495007e-12, 1.0102006037238098e-11, 1.0191517768598501e-11, 1.071311355599347e-11, 1.0805712227779374e-11, 1.1360411743266408e-11, 1.1456193632630729e-11, 1.2145033242982883e-11, 1.521706892437802e-11, 1.624668108379801e-11, 1.7095982615678018e-11, 1.7095984350401494e-11, 1.9330781766968563e-11, 2.0347791160335582e-11, 2.1560810428700172e-11, 2.2844637639907184e-11, 2.298680863710434e-11, 2.4203222759311416e-11, 2.579242895650591e-11, 2.8771289170559378e-11, 2.893277457893806e-11, 3.851622493167284e-11, 3.851622840111979e-11, 4.058177752175318e-11, 4.077648635414377e-11, 4.296565186967527e-11, 4.5693678007996397e-11, 4.836559625021053e-11, 5.097025926326104e-11, 5.0970547227358054e-11, 5.394994867513603e-11, 5.709986650170862e-11, 6.042964045827048e-11, 6.067036456558483e-11, 6.067037150447874e-11, 7.160011472606698e-11, 7.575480520660705e-11, 8.042403548680355e-11, 8.042404242569745e-11, 8.478353435981134e-11, 8.507077681185748e-11, 8.96849747245021e-11, 9.486322838370143e-11, 9.51675752092207e-11, 1.0033373437634552e-10, 1.1221568813057914e-10, 1.1221569506947304e-10, 1.1254726317577735e-10, 1.2547181349464864e-10, 1.25822657848218e-10, 1.258226717260058e-10, 1.4062571940254287e-10, 1.482722972179218e-10, 1.486537837269708e-10, 1.5712993406413744e-10, 1.751097045143979e-10, 1.755236650469172e-10, 1.7823127695937302e-10, 1.8506909893467594e-10, 1.8549482783125626e-10, 1.9803188255895776e-10, 1.9803263195949938e-10, 2.0667792477446767e-10, 2.071273014214725e-10, 2.1838884867175778e-10, 2.2000326560522865e-10, 2.312210978239193e-10, 2.3122111170170712e-10, 2.3187540776348214e-10, 2.43789044507281e-10, 2.443795443785035e-10, 2.5804988701416676e-10, 2.5805038661452784e-10, 2.72069367035499e-10, 2.725815684279098e-10, 2.8791374839798323e-10, 3.0140748230600423e-10, 3.035476314749985e-10, 3.040883655991422e-10, 3.1760563623528526e-10, 3.2115049508618654e-10, 3.385762503693712e-10, 3.526215153204504e-10, 3.575413576317743e-10, 3.581254737206052e-10, 3.7754405157741644e-10, 3.992537966901466e-10, 4.2151157564340735e-10, 4.344692106084125e-10, 4.443369561180077e-10, 4.449833557185201e-10, 4.958202737270767e-10, 5.22627552346222e-10, 5.233238287161157e-10, 5.523153601139086e-10, 6.150829290341164e-10, 6.840125688079013e-10, 6.8479744097516e-10, 7.216873210147412e-10, 7.224924547521994e-10, 7.301563242911868e-10, 7.301577120699676e-10, 7.613870645073462e-10, 8.032132736701669e-10, 8.040589305480239e-10, 8.472797463632276e-10, 8.481439439655958e-10, 8.937031670264162e-10, 8.94587681710135e-10, 8.976534515703349e-10, 9.426062153039538e-10, 9.435116021805356e-10, 9.451186500086806e-10, 9.950423818239074e-10, 1.0483671708527709e-09, 1.0493130808697515e-09, 1.1028313817718072e-09, 1.1656753340361092e-09, 1.229035762051467e-09, 1.2957545036940132e-09, 1.296792118132828e-09, 1.3539634968751102e-09, 1.3659967601498124e-09, 1.3670574672275393e-09, 1.439948715820094e-09, 1.4998264852295051e-09, 1.5784409335140026e-09, 1.599748888914121e-09, 1.6860068896562552e-09, 1.776790714558274e-09, 1.777973657191012e-09, 1.972881191747433e-09, 2.0799415523242715e-09, 2.1425612395375992e-09, 2.1912915926236565e-09, 2.308444768672757e-09, 2.371402407774781e-09, 2.430348811088834e-09, 2.561338252604628e-09, 2.839732671233719e-09, 2.9033511150799995e-09, 2.9905617981995647e-09, 2.992017744674058e-09, 3.053657104956642e-09, 3.053657327001247e-09, 3.2115823334066818e-09, 3.31599214753453e-09, 3.317508046052353e-09, 3.491394728882824e-09, 3.492940381377707e-09, 3.492940603422312e-09, 3.551836158521837e-09, 3.6757998866931985e-09, 3.86969167820439e-09, 4.073521520098211e-09, 4.075160653371768e-09, 4.51300019577161e-09, 4.749727722241914e-09, 4.751444571127195e-09, 4.7514627787847985e-09, 4.7987307461028195e-09, 4.7987485096712135e-09, 5.0002655349601355e-09, 5.044600293047097e-09, 5.259950697222848e-09, 5.302806638241009e-09, 5.573940864422866e-09, 5.823341364674661e-09, 5.823341808763871e-09, 5.82521009206971e-09, 6.12663741961228e-09, 6.157493182001872e-09, 6.471306601696369e-09, 6.780001893247345e-09, 6.800728868938677e-09, 7.131606416521663e-09, 7.890536224408606e-09, 7.890537112587026e-09, 7.890891495776486e-09, 8.290427011559132e-09, 8.723946010036343e-09, 8.726098954525696e-09, 9.150522117806759e-09, 9.175314730214268e-09, 1.0097637392902925e-08, 1.013994666010376e-08, 1.0142211515073996e-08, 1.0659753968411678e-08, 1.066205701505396e-08, 1.120546677668699e-08, 1.1207786698719246e-08, 1.1700342028575506e-08, 1.1778247710481082e-08, 1.3010380328637439e-08, 1.301286456367734e-08, 1.3672546650411732e-08, 1.42286360471644e-08, 1.4367351752753166e-08, 1.5096434324846086e-08, 1.5099011818620056e-08, 1.5861340685319192e-08, 1.6467431862565718e-08, 1.7505733751477237e-08, 1.8388842448757714e-08, 1.9048671973109776e-08, 1.9048673749466616e-08, 1.931510595909458e-08, 1.931792503739871e-08, 2.202293103437114e-08, 2.2373841446210463e-08, 2.23767511187134e-08, 2.3111484281912453e-08, 2.3494184375749683e-08, 2.349717931338091e-08, 2.4671839682355312e-08, 2.5448121832027937e-08, 2.5900424915903386e-08, 2.5903457157028242e-08, 2.7191571660978298e-08, 2.71946465346673e-08, 3.083219723976072e-08, 3.083225408317958e-08, 3.2342711620003683e-08, 3.301229867247457e-08, 3.301230222518825e-08, 3.464555220489274e-08, 3.55830280795999e-08, 3.6357057808800164e-08, 3.731963005293437e-08, 3.913843116265525e-08, 3.913843471536893e-08, 4.002908227107582e-08, 4.104348860778373e-08, 4.303877787492638e-08, 4.7316063955804566e-08, 4.8478700165333066e-08, 4.960711663670736e-08, 5.0851987509759056e-08, 5.2005855621928276e-08, 5.714640138876348e-08, 5.989854656718308e-08, 6.150344233901706e-08, 6.277952024902334e-08, 6.895077575563846e-08, 6.895091075875825e-08, 7.43018517823657e-08, 7.5710083535796e-08, 7.932698053991771e-08, 8.162888320839556e-08, 8.162889031382292e-08, 8.311098298463548e-08, 8.555225861073268e-08, 8.707051790679543e-08, 8.966210174321532e-08, 9.121287547486645e-08, 9.554629798458336e-08, 9.845340542824488e-08, 1.000791911565102e-07, 1.0482041545856191e-07, 1.0807129768863888e-07, 1.0977974085335518e-07, 1.1321786530515965e-07, 1.1322224224841193e-07, 1.203901831559051e-07, 1.242311924443129e-07, 1.2606193422470824e-07, 1.2606206212240068e-07, 1.301241780993223e-07, 1.3819371247336676e-07, 1.4271702752921556e-07, 1.446767754487155e-07, 1.494501589149877e-07, 1.5853922263886489e-07, 1.7368624583014025e-07, 1.7959214915208577e-07, 1.8177649963035947e-07, 1.879939759419358e-07, 1.8799880763253896e-07, 1.9023117658889532e-07, 1.9678553542235022e-07, 2.0829952518397477e-07, 2.1555986506882618e-07, 2.1556459728344635e-07, 2.280246036434619e-07, 2.360656026212382e-07, 2.3607060484209796e-07, 2.584541789474315e-07, 2.9867385364923393e-07, 3.095287581800221e-07, 3.095342719916516e-07, 3.237523173993395e-07, 3.266210057972785e-07, 3.386015237083484e-07, 3.415282208152348e-07, 3.541022977060493e-07, 3.5410758414400334e-07, 3.5709317103282956e-07, 3.702913033976074e-07, 3.7334280023060273e-07, 4.424981625561486e-07, 4.6592452918048366e-07, 4.835179083784169e-07, 5.053755103290314e-07, 5.281897870190733e-07, 5.317453997122357e-07, 5.51996492959006e-07, 5.52000585685164e-07, 5.520021773008921e-07, 5.768409891970805e-07, 6.027584618095716e-07, 6.06509672707034e-07, 6.297969434854167e-07, 6.618900556532026e-07, 6.874158202663239e-07, 7.181099590525264e-07, 7.221405553536897e-07, 7.834884740987036e-07, 8.18296712168376e-07, 8.545935088477563e-07, 8.968428346634028e-07, 8.968428915068216e-07, 9.318973184235801e-07, 9.319032301391417e-07, 9.319058449364093e-07, 9.363743629364762e-07, 9.730341616887017e-07, 9.730383681016974e-07, 1.0205440048594028e-06, 1.060616341419518e-06, 1.0653230901880306e-06, 1.1072072538809152e-06, 1.1072131655964768e-06, 1.107216348827933e-06, 1.1557719972188352e-06, 1.206374236062402e-06, 1.2063801477779634e-06, 1.25911253689992e-06, 1.2591185623023193e-06, 1.2641343118957593e-06, 1.264134425582597e-06, 1.3140643204678781e-06, 1.3713232647205587e-06, 1.4309861171568627e-06, 1.4931301848264411e-06, 1.4931360965420026e-06, 1.56330281697592e-06, 1.5633041812179727e-06, 1.6253134162980132e-06, 1.6253178500846843e-06, 1.6308242720697308e-06, 1.6955573300947435e-06, 1.6955633554971428e-06, 1.7687183344605728e-06, 1.768724359862972e-06, 1.7743989246810088e-06, 1.8449088656780077e-06, 1.8449202343617799e-06, 1.9242540929553797e-06, 2.0068796402483713e-06, 2.0068798676220467e-06, 2.0128097730776062e-06, 2.0929001038894057e-06, 2.1824635041411966e-06, 2.1824716895935126e-06, 2.188574399042409e-06, 2.275706947330036e-06, 2.372770723013673e-06, 2.3790539671608713e-06, 2.473810809533461e-06, 2.473816948622698e-06, 2.4801818199193804e-06, 2.578977955636219e-06, 2.585436959634535e-06, 2.6884308681474067e-06, 2.8023412141919835e-06, 2.802347580654896e-06, 2.8089721126889344e-06, 2.9208763407950755e-06, 2.920882252510637e-06, 2.92760137199366e-06, 2.9736609121755464e-06, 3.1725589906272944e-06, 3.172565357090207e-06, 3.1794634196558036e-06, 3.213507625332568e-06, 3.2135105811903486e-06, 3.3060853183997096e-06, 3.306091230115271e-06, 3.4449906252120854e-06, 3.4520746794441948e-06, 3.4520749068178702e-06, 3.4722361306194216e-06, 3.5895016026188387e-06, 3.5895077417080756e-06, 3.6091321362619055e-06, 3.7398056065285346e-06, 3.747070877579972e-06, 3.7470817915163934e-06, 3.7512920698645758e-06, 3.896158887073398e-06, 3.903497599822003e-06, 4.058745162183186e-06, 4.066191195306601e-06, 4.2278556975361425e-06, 4.235386768414173e-06, 4.376654487714404e-06, 4.403683306009043e-06, 4.411324880493339e-06, 4.548259312286973e-06, 4.586539489537245e-06, 4.586545401252806e-06, 4.776648893312085e-06, 4.776654805027647e-06, 4.7844587243162096e-06, 4.9113637032860424e-06, 4.974308467353694e-06, 4.974313924321905e-06, 5.187791430216748e-06, 5.393394076236291e-06, 5.401467660703929e-06, 5.6154140111175366e-06, 5.615419922833098e-06, 5.6235890042444225e-06, 5.72432873013895e-06, 6.086030680307886e-06, 6.094391665101284e-06, 6.335275429592002e-06, 6.335281341307564e-06, 6.343721906887367e-06, 6.602821031265194e-06, 6.8634112722065765e-06, 7.14303359927726e-06, 7.151750651246402e-06, 7.433532118739095e-06, 7.735334293101914e-06, 7.74421732785413e-06, 8.048824383877218e-06, 8.057804734562524e-06, 8.372642696485855e-06, 8.372665433853399e-06, 8.374447133974172e-06, 8.374451681447681e-06, 8.712639100849628e-06, 8.721821359358728e-06, 9.063895049621351e-06, 9.073130968317855e-06, 9.428645171283279e-06, 9.437976586923469e-06, 9.737053915159777e-06, 9.807399692363106e-06, 9.816819328989368e-06, 1.0110541552421637e-05, 1.020065974444151e-05, 1.0210192158410791e-05, 1.0608975571813062e-05, 1.0608981938275974e-05, 1.0618553460517433e-05, 1.103286376746837e-05, 1.1316221389279235e-05, 1.1472926416900009e-05, 1.1929686479561497e-05, 1.2403800610627513e-05, 1.2413734111760277e-05, 1.28958536151913e-05, 1.2905868061352521e-05, 1.3142303032509517e-05, 1.3406523976300377e-05, 1.4159289094095584e-05, 1.4486291547655128e-05, 1.4486294276139233e-05, 1.4695945537823718e-05, 1.505678392277332e-05, 1.5056789379741531e-05, 1.564869307912886e-05, 1.5659112250432372e-05, 1.689968121354468e-05, 1.6899686670512892e-05, 1.757103018462658e-05, 1.8256376279168762e-05, 1.8353164705331437e-05, 1.8967140931636095e-05, 1.9693319700309075e-05, 1.9756940673687495e-05, 2.0468462025746703e-05, 2.124992897734046e-05, 2.207150828326121e-05, 2.2881567929289304e-05, 2.2923199139768258e-05, 2.292320459673647e-05, 2.2934365915716626e-05, 2.3734213755233213e-05, 2.3734215574222617e-05, 2.4617367671453394e-05, 2.4721361114643514e-05, 2.473266067681834e-05, 2.566996408859268e-05, 2.566996954556089e-05, 2.568133277236484e-05, 2.5681334591354243e-05, 2.647962173796259e-05, 2.665308056748472e-05, 2.7671958378050476e-05, 2.8727743483614177e-05, 2.8739301342284307e-05, 3.095519059570506e-05, 3.095519423368387e-05, 3.212950105080381e-05, 3.212950468878262e-05, 3.214121170458384e-05, 3.2141240808414295e-05, 3.291505345259793e-05, 3.291508255642839e-05, 3.335781366331503e-05, 3.412426667637192e-05, 3.460618609096855e-05, 3.537612792570144e-05, 3.591137647163123e-05, 3.667198325274512e-05, 3.726327122421935e-05, 3.726327486219816e-05, 3.727523289853707e-05, 3.866326005663723e-05, 3.8663263694616035e-05, 3.9401493268087506e-05, 4.0113056456902996e-05, 4.083836029167287e-05, 4.161428296356462e-05, 4.232530773151666e-05, 4.316867853049189e-05, 4.645616718335077e-05, 4.7103792894631624e-05, 4.710379653261043e-05, 4.8168541979976e-05, 4.8808356950758025e-05, 4.995361450710334e-05, 4.9953618145082146e-05, 4.995362542103976e-05, 4.996595089323819e-05, 5.1813447498716414e-05, 5.239621168584563e-05, 5.569208587985486e-05, 5.570452776737511e-05, 5.623533434118144e-05, 5.77396058361046e-05, 5.775207682745531e-05, 5.9858266467927024e-05, 5.987066469970159e-05, 6.205014506122097e-05, 6.250183650990948e-05, 6.666354602202773e-05, 6.667633715551347e-05, 6.909009243827313e-05, 7.159974484238774e-05, 7.190012547653168e-05, 7.41954063414596e-05, 7.419541361741722e-05, 7.420808105962351e-05, 7.687963807256892e-05, 7.981735689099878e-05, 8.252533007180318e-05, 8.549282938474789e-05, 8.856048953020945e-05, 8.856049680616707e-05, 8.856055501382798e-05, 8.857348439050838e-05, 9.820986451813951e-05, 9.83985883067362e-05, 9.841138671617955e-05, 0.00010164269042434171, 0.00010190048487856984, 0.00010191347246291116, 0.00010553249012446031, 0.00010885298979701474, 0.0001092594611691311, 0.00010927225957857445, 0.0001131239187088795, 0.00011313670984236524, 0.00011711683328030631, 0.00012475595576688647, 0.00012475620314944535, 0.00012550325482152402, 0.00012906284246128052, 0.00012990509276278317, 0.0001299178838962689, 0.00012991789844818413, 0.00013446478988043964, 0.00013810327800456434, 0.0001391610858263448, 0.00014284545613918453, 0.0001439979678252712, 0.00014774080773349851, 0.00014774106966797262, 0.0001490061986260116, 0.0001490189169999212, 0.00015279532817658037, 0.00015417776012327522, 0.00015801299014128745, 0.0001650305202929303, 0.00016895779117476195, 0.0001689581258688122, 0.0001707216288195923, 0.00017072164337150753, 0.00017469543672632426, 0.0001765969645930454, 0.00017660959565546364, 0.00018061698938254267, 0.00018266114057041705, 0.00018892048683483154, 0.00019303298904560506, 0.00019953877199441195, 0.0002020465472014621, 0.00020205909095238894, 0.0002062514249701053, 0.00020892548491246998, 0.00021602366177830845, 0.00022032026026863605, 0.00022032068227417767, 0.00022334673849400133, 0.00023091443290468305, 0.00023529090685769916, 0.00024313072208315134, 0.00024673546431586146, 0.0002467354934196919, 0.00025121535873040557, 0.0002550274657551199, 0.00025955334422178566, 0.0002635922865010798, 0.00026815131423063576, 0.00027701660292223096, 0.00028149515856057405, 0.00028150764410384, 0.00028615668998099864, 0.0002908736641984433, 0.0002955796953756362, 0.0003005429753102362, 0.0003052940883208066, 0.0003105125215370208, 0.00031051255064085126, 0.000310524512315169, 0.00032078943331725895, 0.00032562922569923103, 0.00033138386788778007, 0.0003362673451192677, 0.0003362676652614027, 0.0003423037414904684, 0.00034231552854180336, 0.0003585298254620284, 0.0003651579609140754, 0.0003651580191217363, 0.00037017217255197465, 0.00037711180630140007, 0.000377111864509061, 0.00039452852797694504, 0.0004021208151243627, 0.0004151964094489813, 0.0004203809075988829, 0.00042866807780228555, 0.0004286794282961637, 0.00043389335041865706, 0.0004425451625138521, 0.0004425452498253435, 0.0004425565421115607, 0.0004478116170503199, 0.00045684041106142104, 0.0004568516742438078, 0.0004769120132550597, 0.0004867278621532023, 0.0004867279785685241, 0.0004867383395321667, 0.0005023445119149983, 0.0005077716195955873, 0.0005184264737181365, 0.0005184374749660492, 0.0005520355771295726, 0.0005520452978089452, 0.0006119171739555895, 0.0006254090694710612, 0.000625409244094044, 0.0006254205363802612, 0.0006451267399825156, 0.0006508430233225226, 0.0006653993623331189, 0.0006654094904661179, 0.0006711609894409776, 0.0006862721056677401, 0.0006862723967060447, 0.0006862824084237218, 0.0006920685991644859, 0.000707749743014574, 0.0007077499176375568, 0.000713581161107868, 0.0007525882101617754, 0.0007759814616292715, 0.0008000458474270999, 0.0008000554516911507, 0.0008248009835369885, 0.000830792065244168, 0.0008502618875354528, 0.000850271200761199, 0.0008502712589688599, 0.0008764493977651, 0.000903380278032273, 0.0009033808019012213, 0.0009094620472751558, 0.0009310762980021536, 0.0009310850291512907, 0.0009310858440585434, 0.0009595545707270503, 0.0009595634764991701, 0.0009888370987027884, 0.0009888458298519254, 0.0009949997765943408, 0.0010189417516812682, 0.0010189511813223362, 0.0010498921619728208, 0.0010561065282672644, 0.0010817060247063637, 0.0010817067231982946, 0.0011144111631438136, 0.0011144193122163415, 0.0011206743074581027, 0.0011480243410915136, 0.0011825700057670474, 0.0012180726043879986, 0.0012545562349259853, 0.001298417686484754, 0.001298417802900076, 0.0013305606553331017, 0.0013305619359016418, 0.0013305690372362733, 0.0013305708998814225, 0.0013369530206546187, 0.0013701335992664099, 0.0013701393036171794, 0.0014172135852277279, 0.0014525451697409153, 0.001452546683140099, 0.0014589912025257945, 0.0014954372309148312, 0.001495445379987359, 0.00149544735904783, 0.0015394994989037514, 0.0015847376780584455, 0.0015847394242882729, 0.0015847454778850079, 0.001631203223951161, 0.001631205203011632, 0.0016312109073624015, 0.0016377089777961373, 0.0016377090942114592, 0.0016789149958640337, 0.0016789170913398266, 0.001727905124425888, 0.0017782063223421574, 0.001778211328200996, 0.0018298429204151034, 0.0018298501381650567, 0.0018828551983460784, 0.0018894142704084516, 0.001889416016638279, 0.0019372673705220222, 0.0019372726092115045, 0.0019438359886407852, 0.001993118319660425, 0.0019931215792894363, 0.001993125304579735, 0.0020504428539425135, 0.002050449838861823, 0.0020570282358676195, 0.0021092682145535946, 0.0021092721726745367, 0.0021092784591019154, 0.00216963910497725, 0.002169643295928836, 0.0022315888199955225, 0.0022381825838238, 0.002295141341164708, 0.002295145997777581, 0.002360348356887698, 0.0023603534791618586, 0.002360357204452157, 0.0023669572547078133, 0.002366957487538457, 0.0024272450245916843, 0.002495866734534502, 0.0025024760980159044, 0.0025662563275545835, 0.002566262613981962, 0.0025728654582053423, 0.0026384531520307064, 0.0026450585573911667, 0.002712492598220706, 0.0027884242590516806, 0.002788429381325841, 0.0027884303126484156, 0.0027950250077992678, 0.0028662835247814655, 0.002866289345547557, 0.0028728831093758345, 0.0029461297672241926, 0.002946131397038698, 0.0030279727652668953, 0.0030279788188636303, 0.0030345625709742308, 0.003084785770624876, 0.003111893543973565, 0.0031118993647396564, 0.0031979160849004984, 0.00319792702794075, 0.0032044921535998583, 0.003204492386430502, 0.0032422689255326986, 0.0032422735821455717, 0.003286099759861827, 0.003286105114966631, 0.0032861114013940096, 0.003376479959115386, 0.0033764957915991545, 0.0033830394968390465, 0.003383042523637414, 0.0034073381684720516, 0.0034691200125962496, 0.003475659294053912, 0.0034928240347653627, 0.003564046695828438, 0.0035640608984977007, 0.0035705852787941694, 0.0035803329665213823, 0.0036613340489566326, 0.0036613442935049534, 0.003667856100946665, 0.0037610079161822796, 0.003767525078728795, 0.003863143501803279, 0.0038631483912467957, 0.0039514582604169846, 0.003967778291553259, 0.003967782948166132, 0.003967796918004751, 0.003974265418946743, 0.004049744922667742, 0.004074972588568926, 0.004074977245181799, 0.00407499261200428, 0.00418480159714818, 0.00419123750180006, 0.004253253806382418, 0.004297246225178242, 0.004297265317291021, 0.004297269508242607, 0.004303683061152697, 0.00441243639215827, 0.004412441048771143, 0.004418859723955393, 0.004651218187063932, 0.004651252645999193, 0.004657610319554806, 0.004689392168074846, 0.0047749243676662445, 0.00477492855861783, 0.004774949979037046, 0.0047749546356499195, 0.004781290423125029, 0.004907930735498667, 0.0050312611274421215, 0.005164020229130983, 0.005170322023332119, 0.005299913696944714, 0.005439022555947304, 0.005445265211164951, 0.005581386853009462, 0.0055814278312027454, 0.0055876136757433414, 0.005727089010179043, 0.005727092735469341, 0.005876194220036268, 0.005882378201931715, 0.00596947455778718, 0.005969482474029064, 0.006028770934790373, 0.006028815638273954, 0.006034911144524813, 0.006184875499457121, 0.006184929981827736, 0.0061909970827400684, 0.006344597786664963, 0.0063446564599871635, 0.006350688636302948, 0.006507986690849066, 0.006508053746074438, 0.006508059799671173, 0.0065140617080032825, 0.006567105185240507, 0.006675130687654018, 0.006675134412944317, 0.0066811637952923775, 0.0066811698488891125, 0.0067249322310090065, 0.006846095900982618, 0.007020965218544006, 0.007021042052656412, 0.007021042518317699, 0.007199794054031372, 0.007219704333692789, 0.007382678333669901, 0.007382767274975777, 0.00738859036937356, 0.007569677662104368, 0.007575555704534054, 0.0077608851715922356, 0.007931631058454514, 0.008156212978065014, 0.008156214840710163, 0.008311295881867409, 0.008360493928194046, 0.00836049672216177, 0.008360623382031918, 0.008507316000759602, 0.008569312281906605, 0.008569442667067051, 0.0085750175639987, 0.008782869204878807, 0.00900083314627409, 0.009000835940241814, 0.00900097656995058, 0.009229312650859356, 0.00945703312754631, 0.00968969613313675, 0.00977496337145567, 0.009921911172568798, 0.009922118857502937, 0.010170216672122478, 0.010234343819320202, 0.010412869043648243, 0.010413089767098427, 0.010666283778846264, 0.010925080627202988, 0.010925082489848137, 0.01092534139752388, 0.01093040220439434, 0.011212402954697609, 0.011459283530712128, 0.011459565721452236, 0.011464521288871765, 0.011469792574644089, 0.01146980281919241, 0.011732512153685093, 0.01173488236963749, 0.011734884232282639, 0.011735178530216217, 0.011740075424313545, 0.011740079149603844, 0.012016259133815765, 0.012016577646136284, 0.012274304404854774, 0.012303531169891357, 0.012596777640283108, 0.012601845897734165, 0.013201632536947727, 0.013201634399592876, 0.013513460755348206, 0.013513462617993355, 0.0135183809325099, 0.013518398627638817, 0.013836563564836979, 0.01403746660798788, 0.014037486165761948, 0.014156381599605083, 0.014156869612634182, 0.01435244083404541, 0.01448768936097622, 0.014673742465674877, 0.014825721271336079, 0.014825722202658653, 0.014830479398369789, 0.015001440420746803, 0.015170558355748653, 0.015170560218393803, 0.015171156264841557, 0.015522340312600136, 0.015676459297537804, 0.015881149098277092, 0.016024017706513405, 0.016247116029262543, 0.01624780148267746, 0.016378404572606087, 0.017001720145344734, 0.01700541563332081, 0.017389023676514626, 0.017483623698353767, 0.01748363859951496, 0.01778470166027546, 0.01778470352292061, 0.017789093777537346, 0.01786644011735916, 0.018192443996667862, 0.01819245144724846, 0.018600352108478546, 0.018654324114322662, 0.01901855506002903, 0.019022803753614426, 0.019445814192295074, 0.01945001445710659, 0.019472673535346985, 0.01988128200173378, 0.019885417073965073, 0.020325038582086563, 0.02032630145549774, 0.020759332925081253, 0.02123800478875637, 0.021242043003439903, 0.021707458421587944, 0.022185686975717545, 0.02218727208673954, 0.02259034290909767, 0.022672871127724648, 0.022672872990369797, 0.0226767435669899, 0.023169077932834625, 0.02405441366136074, 0.024189194664359093, 0.02471335418522358, 0.024715464562177658, 0.025247052311897278, 0.025250697508454323, 0.025600120425224304, 0.025600124150514603, 0.025792811065912247, 0.026346201077103615, 0.026906883344054222, 0.02690953202545643, 0.026909535750746727, 0.026910383254289627, 0.027230871841311455, 0.027480145916342735, 0.02748362347483635, 0.02779397740960121, 0.028067057952284813, 0.02865748293697834, 0.028660839423537254, 0.028950195759534836, 0.029261836782097816, 0.029265146702528, 0.029876800253987312, 0.029880300164222717, 0.0305061973631382, 0.031139109283685684, 0.031142987310886383, 0.031386636197566986, 0.031386662274599075, 0.0317867211997509, 0.03178985044360161, 0.03178985416889191, 0.03179085627198219, 0.032022323459386826, 0.032448600977659225, 0.033118680119514465, 0.0333266519010067, 0.03379715606570244, 0.03380199894309044, 0.03399551659822464, 0.034490253776311874, 0.03449320048093796, 0.03467565402388573, 0.034675683826208115, 0.03519509360194206, 0.035367317497730255, 0.03607058897614479, 0.036640431731939316, 0.03738122805953026, 0.03738123178482056, 0.03738761320710182, 0.037512410432100296, 0.03751244395971298, 0.03813430666923523, 0.038137033581733704, 0.03825133293867111, 0.038899779319763184, 0.03900239244103432, 0.039677828550338745, 0.03968529403209686, 0.04054155573248863, 0.04127212241292, 0.04127468541264534, 0.04132993519306183, 0.042088642716407776, 0.04209747537970543, 0.042131051421165466, 0.04291832074522972, 0.042927589267492294, 0.043761204928159714, 0.04377098008990288, 0.04377198591828346, 0.04377202317118645, 0.044619932770729065, 0.045465607196092606, 0.04549824446439743, 0.04549827054142952, 0.04633248224854469, 0.046332504600286484, 0.04637089744210243, 0.04637090116739273, 0.04637090489268303, 0.046382348984479904, 0.047212887555360794, 0.04726822301745415, 0.0481070950627327, 0.048181794583797455, 0.04819226264953613, 0.04901513457298279, 0.049937184900045395, 0.04993719607591629, 0.05004463344812393, 0.05004683509469032, 0.05087336525321007, 0.05099869519472122, 0.05182383581995964, 0.05196724459528923, 0.05278876796364784, 0.05295049026608467, 0.05295049771666527, 0.052952513098716736, 0.05394851416349411, 0.05394851788878441, 0.05396582558751106, 0.05476244166493416, 0.05496150627732277, 0.055771466344594955, 0.05577150359749794, 0.05598956346511841, 0.05599148944020271, 0.057053014636039734, 0.05783473700284958, 0.058091484010219574, 0.05809149518609047, 0.05811271071434021, 0.05811275541782379, 0.058889176696538925, 0.05916565656661987, 0.05916566401720047, 0.061044469475746155, 0.061361003667116165, 0.06138569489121437, 0.06248243525624275, 0.06326259672641754, 0.06361998617649078, 0.06362167000770569, 0.0643954873085022, 0.06477363407611847, 0.06477364152669907, 0.06477533280849457, 0.06480231881141663, 0.06480235606431961, 0.06554446369409561, 0.0659436583518982, 0.06594528257846832, 0.06597379595041275, 0.06789139658212662, 0.06833310425281525, 0.06833311915397644, 0.06833460927009583, 0.0683663934469223, 0.06955282390117645, 0.07030423730611801, 0.0707893893122673, 0.07079089432954788, 0.0720815360546112, 0.07331355661153793, 0.07331494241952896, 0.07464390248060226, 0.07595124840736389, 0.07727616280317307, 0.07794961333274841, 0.0779496431350708, 0.07856953144073486, 0.07856954634189606, 0.0785709097981453, 0.07992879301309586, 0.08063700795173645, 0.08130335807800293, 0.08130459487438202, 0.08135748654603958, 0.08200734853744507, 0.08269711583852768, 0.08269715309143066, 0.08269833773374557, 0.08339560776948929, 0.08410893380641937, 0.08410895615816116, 0.08480189740657806, 0.08698735386133194, 0.08845414221286774, 0.08852282911539078, 0.08993939310312271, 0.08994047343730927, 0.09001141041517258, 0.09144333750009537, 0.09210754930973053, 0.0929659754037857, 0.09296698868274689, 0.09296699613332748, 0.09450746327638626, 0.0960678979754448, 0.09606795012950897, 0.09615485370159149, 0.09615489095449448, 0.09671458601951599, 0.09764745086431503, 0.09764837473630905, 0.09764844924211502, 0.09773842990398407, 0.09924613684415817, 0.0992470532655716, 0.099341481924057, 0.10086408257484436, 0.1008649691939354, 0.10096391290426254, 0.10149269551038742, 0.1025012880563736, 0.10250220447778702, 0.1026059240102768, 0.10415802896022797, 0.1042674109339714, 0.10477454215288162, 0.10583411902189255, 0.10583418607711792, 0.10753005743026733, 0.10753084719181061, 0.107650026679039, 0.10813438892364502, 0.10924553126096725, 0.10937117040157318, 0.11098077148199081, 0.11273586750030518, 0.11287344992160797, 0.11451099812984467, 0.11645665019750595, 0.11687973886728287, 0.11687979102134705, 0.11812123656272888, 0.11812134832143784, 0.11812198162078857, 0.11812206357717514, 0.11827871948480606, 0.11868871748447418, 0.11995657533407211, 0.11995723098516464, 0.12012118846178055, 0.12236711382865906, 0.12368785589933395, 0.1236879825592041, 0.12386791408061981, 0.12423674017190933, 0.12558391690254211, 0.12558460235595703, 0.125584676861763, 0.12577223777770996, 0.12750102579593658, 0.12769711017608643, 0.12943732738494873, 0.12943747639656067, 0.12943796813488007, 0.13139477372169495, 0.13139495253562927, 0.1313953995704651, 0.13160958886146545, 0.13191883265972137, 0.13337266445159912, 0.13337284326553345, 0.13537122309207916, 0.13560569286346436, 0.13739047944545746, 0.1373908668756485, 0.1376352161169052, 0.13943009078502655, 0.13943064212799072, 0.13968588411808014, 0.1414906531572342, 0.14175766706466675, 0.1419835388660431, 0.14198365807533264, 0.1435716152191162, 0.14357203245162964, 0.1438504010438919, 0.14385052025318146, 0.1440584361553192, 0.14567337930202484, 0.14567363262176514, 0.14567390084266663, 0.14779599010944366, 0.14779649674892426, 0.14809991419315338, 0.14827066659927368, 0.14993926882743835, 0.14993953704833984, 0.14993984997272491, 0.15210337936878204, 0.15210367739200592, 0.15243439376354218, 0.154288649559021, 0.15428867936134338, 0.15474453568458557, 0.15649382770061493, 0.1564941555261612, 0.15685415267944336, 0.15872015058994293, 0.1587204933166504, 0.1587207019329071, 0.1590961217880249, 0.15916447341442108, 0.15916451811790466, 0.16096730530261993, 0.16323509812355042, 0.1636439710855484, 0.16366736590862274, 0.16552375257015228, 0.16552415490150452, 0.16595003008842468, 0.1678331047296524, 0.16825337707996368, 0.1682775467634201, 0.17016299068927765, 0.17251364886760712, 0.17251402139663696, 0.17251403629779816, 0.17292208969593048, 0.1729964166879654, 0.17299647629261017, 0.1748848259449005, 0.17488518357276917, 0.17528748512268066, 0.17727713286876678, 0.17727719247341156, 0.1778009980916977, 0.17968890070915222, 0.17968925833702087, 0.18007995188236237, 0.18212172389030457, 0.18212205171585083, 0.18212218582630157, 0.18457484245300293, 0.18457546830177307, 0.18495438992977142, 0.18495440483093262, 0.18516764044761658, 0.18704842031002045, 0.18704873323440552, 0.18704909086227417, 0.18954212963581085, 0.1895429790019989, 0.18991035223007202, 0.18991048634052277, 0.19018512964248657, 0.19205652177333832, 0.1924186795949936, 0.19272541999816895, 0.1927255243062973, 0.19459030032157898, 0.19459106028079987, 0.19494730234146118, 0.1971447914838791, 0.19714535772800446, 0.1974959820508957, 0.19896893203258514, 0.19971859455108643, 0.20006464421749115, 0.202312633395195, 0.2023128867149353, 0.2033974975347519, 0.20339761674404144, 0.20492631196975708, 0.20492658019065857, 0.20492728054523468, 0.2052614390850067, 0.20574364066123962, 0.2075597643852234, 0.2075599879026413, 0.20756077766418457, 0.20789699256420135, 0.2101733237504959, 0.2102138251066208, 0.2105371206998825, 0.21246735751628876, 0.21288499236106873, 0.2128860205411911, 0.21288613975048065, 0.21320395171642303, 0.21557655930519104, 0.21557678282260895, 0.21589039266109467, 0.21653322875499725, 0.2192821204662323, 0.22101713716983795, 0.22101862728595734, 0.2213207185268402, 0.221819207072258, 0.22376589477062225, 0.22376611828804016, 0.22376717627048492, 0.22376732528209686, 0.22406424582004547, 0.22420097887516022, 0.2248409241437912, 0.22682656347751617, 0.22765059769153595, 0.22765062749385834, 0.2290167361497879, 0.2290167659521103, 0.2293192744255066, 0.2321237474679947, 0.23240701854228973, 0.23494626581668854, 0.23778721690177917, 0.2380603551864624, 0.23885533213615417, 0.24064572155475616, 0.24064749479293823, 0.24091419577598572, 0.24199818074703217, 0.24352188408374786, 0.2435220330953598, 0.24641574919223785, 0.24667485058307648, 0.24787428975105286, 0.2493268996477127, 0.24932889640331268, 0.24958105385303497, 0.2522549629211426, 0.25225719809532166, 0.2525046467781067, 0.2538270950317383, 0.255200058221817, 0.25520241260528564, 0.25544512271881104, 0.2581615149974823, 0.2581641674041748, 0.25816431641578674, 0.25840240716934204, 0.26113972067832947, 0.261139839887619, 0.2613758444786072, 0.26137590408325195, 0.26289722323417664, 0.26413393020629883, 0.26462802290916443, 0.26462820172309875, 0.26714441180229187, 0.26714733242988586, 0.27017030119895935, 0.2721327543258667, 0.2732117772102356, 0.27321508526802063, 0.27343055605888367, 0.27538883686065674, 0.27626833319664, 0.27648288011550903, 0.2781176269054413, 0.2793399691581726, 0.2855266034603119, 0.28552669286727905, 0.2863940894603729, 0.2878786027431488, 0.28864115476608276, 0.2886412739753723, 0.28864556550979614, 0.2910791337490082, 0.29176977276802063, 0.2917742133140564, 0.29196402430534363, 0.29429617524147034, 0.2949163615703583, 0.2975296378135681, 0.2976323068141937, 0.2980666756629944, 0.29806673526763916, 0.29807156324386597, 0.30141738057136536, 0.30333495140075684, 0.30404433608055115, 0.3040443956851959, 0.3045942485332489, 0.30620646476745605, 0.3077833354473114, 0.3108125329017639, 0.31081873178482056, 0.31419673562049866, 0.31725600361824036, 0.3172627389431, 0.3204943537712097, 0.323702335357666, 0.32374292612075806, 0.3237430155277252, 0.32375049591064453, 0.32390064001083374, 0.32395684719085693, 0.329630047082901, 0.33027034997940063, 0.3302784860134125, 0.3304213285446167, 0.33070993423461914, 0.33354830741882324, 0.333548367023468, 0.33355680108070374, 0.3336959779262543, 0.33369600772857666, 0.33683520555496216, 0.3368441164493561, 0.3375176191329956, 0.34013083577156067, 0.3409411311149597, 0.3416159749031067, 0.34343448281288147, 0.3435726463794708, 0.34437716007232666, 0.34463798999786377, 0.34463804960250854, 0.3476695716381073, 0.3500649034976959, 0.3500649333000183, 0.35128670930862427, 0.3533908724784851, 0.3533909320831299, 0.35351988673210144, 0.353520005941391, 0.3537602424621582, 0.3568496108055115, 0.358243465423584, 0.3600620627403259, 0.3600744605064392, 0.36173883080482483, 0.36340630054473877, 0.36675599217414856, 0.36675602197647095, 0.36687371134757996, 0.3687620759010315, 0.36876219511032104, 0.37011030316352844, 0.37011033296585083, 0.3701247274875641, 0.37222856283187866, 0.3722286522388458, 0.3722892999649048, 0.3734692335128784, 0.37533143162727356, 0.376831978559494, 0.3784407377243042, 0.3793732225894928, 0.38019829988479614, 0.38021448254585266, 0.38155579566955566, 0.38292941451072693, 0.38649433851242065, 0.3869573473930359, 0.3870414197444916, 0.3878015875816345, 0.390067994594574, 0.39006808400154114, 0.39031341671943665, 0.3909318149089813, 0.3936500549316406, 0.3936888575553894, 0.3936888873577118, 0.3936889171600342, 0.39378607273101807, 0.3940662443637848, 0.39716029167175293, 0.3971603512763977, 0.3972400724887848, 0.40046441555023193, 0.40083783864974976, 0.4034908413887024, 0.40349096059799194, 0.4038204848766327, 0.40391069650650024, 0.4044424295425415, 0.40444251894950867, 0.4066382646560669, 0.4071975648403168, 0.40728554129600525, 0.4080543518066406, 0.4105739891529083, 0.4106596112251282, 0.4129391610622406, 0.4139489531517029, 0.4139746427536011, 0.4152972996234894, 0.4152974486351013, 0.4192454218864441, 0.4206930100917816, 0.4207727015018463, 0.4225637912750244, 0.4240611493587494, 0.42620497941970825, 0.4274257719516754, 0.4274563491344452, 0.4287071228027344, 0.42985087633132935, 0.430786669254303, 0.43078672885894775, 0.4308602511882782, 0.4341430962085724, 0.43715566396713257, 0.4408138394355774, 0.44084081053733826, 0.44130852818489075, 0.4441811144351959, 0.44421905279159546, 0.4444754123687744, 0.4444754719734192, 0.44751474261283875, 0.4475792646408081, 0.45073258876800537, 0.45088279247283936, 0.4518069326877594, 0.4518069624900818, 0.45420393347740173, 0.4554763436317444, 0.4574718773365021, 0.4575169086456299, 0.45751693844795227, 0.4575313627719879, 0.45914754271507263, 0.45914772152900696, 0.4601192772388458, 0.4601193070411682, 0.46077433228492737, 0.46083229780197144, 0.4628201723098755, 0.46412405371665955, 0.4664941728115082, 0.4673514664173126, 0.4674062132835388, 0.4694555401802063, 0.47062504291534424, 0.47067826986312866, 0.4725542664527893, 0.47384408116340637, 0.4738878905773163, 0.4739433825016022, 0.4771970808506012, 0.4775189459323883, 0.477519154548645, 0.47872811555862427, 0.48037898540496826, 0.480439156293869, 0.48360615968704224, 0.4836537837982178, 0.48365381360054016, 0.48366907238960266, 0.48686683177948, 0.4900665581226349, 0.4909694790840149, 0.49096962809562683, 0.49221286177635193, 0.49320846796035767, 0.49327942728996277, 0.4940045475959778, 0.49638083577156067, 0.49642321467399597, 0.4995381534099579, 0.4995501637458801, 0.5000410676002502, 0.5030413866043091, 0.5032153725624084, 0.5058054327964783, 0.5060288310050964, 0.5060290098190308, 0.5089142322540283, 0.5089142918586731, 0.5090011358261108, 0.5090035200119019, 0.5119643807411194, 0.5120060443878174, 0.5120426416397095, 0.5141919851303101, 0.5141920447349548, 0.5150798559188843, 0.5178430676460266, 0.5178431868553162, 0.5181355476379395, 0.5182332992553711, 0.5207599997520447, 0.523661196231842, 0.5241897702217102, 0.5242223143577576, 0.5251331925392151, 0.5271872878074646, 0.5272975564002991, 0.5294145345687866, 0.5301645398139954, 0.5302790999412537, 0.5322654843330383, 0.5331206917762756, 0.5332397818565369, 0.5350989103317261, 0.5360292196273804, 0.5360843539237976, 0.5390971302986145, 0.5390971899032593, 0.5407100915908813, 0.5407102704048157, 0.5418587327003479, 0.5418587923049927, 0.5419925451278687, 0.5447260737419128, 0.5462446808815002, 0.5475954413414001, 0.547714352607727, 0.548981785774231, 0.5489818453788757, 0.5504710078239441, 0.5516979694366455, 0.5531852841377258, 0.5532091856002808, 0.5543931722640991, 0.5559556484222412, 0.5570665001869202, 0.558700442314148, 0.55971759557724, 0.5597176551818848, 0.5612257122993469, 0.5614193081855774, 0.5614193677902222, 0.5614409446716309, 0.5623459815979004, 0.5641116499900818, 0.5641117095947266, 0.5642927289009094, 0.5649511218070984, 0.5667771100997925, 0.5675325989723206, 0.5683541297912598, 0.5694150924682617, 0.5694347023963928, 0.5722274780273438, 0.572622537612915, 0.5746066570281982, 0.5746067762374878, 0.5748166441917419, 0.5748168230056763, 0.5751299262046814, 0.5751299858093262, 0.5754464864730835, 0.5771595239639282, 0.5771596431732178, 0.5789783596992493, 0.578978419303894, 0.5800677537918091, 0.5821768641471863, 0.5824111104011536, 0.5824969410896301, 0.5846403241157532, 0.5870732069015503, 0.5870887637138367, 0.5872740745544434, 0.5894747972488403, 0.5894749164581299, 0.5894899964332581, 0.5895130038261414, 0.5897358655929565, 0.5897359251976013, 0.5918450951576233, 0.5918596982955933, 0.5919396877288818, 0.5921156406402588, 0.5930033922195435, 0.5942293405532837, 0.596482515335083, 0.5964890122413635, 0.5964891910552979, 0.5964898467063904, 0.5965026021003723, 0.5967795848846436, 0.5987621545791626, 0.6009215116500854, 0.6010017991065979, 0.6010145545005798, 0.6034060716629028, 0.6035310626029968, 0.6052309274673462, 0.6053801774978638, 0.6053918600082397, 0.6068502068519592, 0.6078640818595886, 0.6099792718887329, 0.6102820038795471, 0.6120595335960388, 0.6137009859085083, 0.6137011051177979, 0.6137203574180603, 0.6137205362319946, 0.6137308478355408, 0.6157265305519104, 0.6173937916755676, 0.6176765561103821, 0.6176859736442566, 0.6180878281593323, 0.6195995807647705, 0.6195998191833496, 0.6196088194847107, 0.6211822628974915, 0.6214856505393982, 0.6214858293533325, 0.6230249404907227, 0.6248329281806946, 0.6251458525657654, 0.6266055107116699, 0.6269189119338989, 0.6274057626724243, 0.6286536455154419, 0.6286612153053284, 0.6291570663452148, 0.6303497552871704, 0.6320068836212158, 0.6320137977600098, 0.6320138573646545, 0.6336244940757751, 0.6339389681816101, 0.6349284052848816, 0.6352027654647827, 0.6352031230926514, 0.635777473449707, 0.6357775330543518, 0.6367412209510803, 0.6367476582527161, 0.6367477774620056, 0.6373348832130432, 0.638239860534668, 0.6382457613945007, 0.6388529539108276, 0.6394782066345215, 0.6396978497505188, 0.6397034525871277, 0.640330970287323, 0.6405733227729797, 0.6411150693893433, 0.6411204934120178, 0.6417690515518188, 0.6424914598464966, 0.6431666612625122, 0.6436845660209656, 0.6438261866569519, 0.6438265442848206, 0.6438684463500977, 0.6438685655593872, 0.64512038230896, 0.645125150680542, 0.6458401083946228, 0.646294355392456, 0.6463724970817566, 0.6471153497695923, 0.6471487283706665, 0.6475821733474731, 0.6487460732460022, 0.6487503051757812, 0.6495420336723328, 0.6498761177062988, 0.6518022418022156, 0.6520001292228699, 0.6520007252693176, 0.6520042419433594, 0.6520043015480042, 0.6528694033622742, 0.6529979109764099, 0.6530018448829651, 0.6538943648338318, 0.6541702747344971, 0.6541703939437866, 0.6548638939857483, 0.6548646092414856, 0.6551324725151062, 0.6557319164276123, 0.655735433101654, 0.6557354927062988, 0.6558172702789307, 0.6565597057342529, 0.6567147970199585, 0.6569324731826782, 0.6573370695114136, 0.6573377847671509, 0.6573402881622314, 0.6575694680213928, 0.657770037651062, 0.658073902130127, 0.6580747365951538, 0.6580770611763, 0.6587668061256409, 0.6587676405906677, 0.6591498851776123, 0.6594154834747314, 0.6600209474563599, 0.6600228548049927, 0.6601158380508423, 0.6605578660964966, 0.6605802178382874, 0.6605828404426575, 0.6606985330581665, 0.6606985926628113, 0.6610969305038452, 0.6611967086791992, 0.6615671515464783, 0.6615695953369141, 0.6617921590805054, 0.6619937419891357, 0.6619948148727417, 0.661996066570282, 0.6623440980911255, 0.6623756289482117, 0.6623778343200684, 0.6627126932144165, 0.6627139449119568, 0.6627148985862732, 0.6628523468971252, 0.663004994392395, 0.6630063056945801, 0.66325443983078, 0.6632544994354248, 0.6633999347686768, 0.6634548902511597, 0.6634562611579895, 0.6636124849319458, 0.6636139154434204, 0.6636142730712891, 0.6637250185012817, 0.6637376546859741, 0.6637377142906189, 0.6637924909591675, 0.6638109087944031, 0.6638150215148926, 0.6638166904449463, 0.6644479036331177, 0.6645029783248901, 0.6649824976921082, 0.665183961391449, 0.6652142405509949, 0.6654549241065979, 0.6654698848724365, 0.6654699444770813, 0.6655246019363403, 0.6655502915382385, 0.6665043234825134, 0.6852715015411377, 0.6883395910263062, 0.6944229006767273, 0.7063748836517334, 0.7151473760604858, 0.7180342674255371, 0.7293938994407654, 0.7293940186500549, 0.7564495205879211, 0.7667251229286194, 0.7717447876930237, 0.7742249965667725, 0.783948540687561, 0.7863302826881409, 0.7886921763420105, 0.7933568954467773, 0.7933569550514221, 0.7979432940483093]\n"
     ]
    }
   ],
   "source": [
    "Xb, yb = next(iter(train_dataloader))\n",
    "print(\"X batch shape:\", Xb.shape, \"dtype:\", Xb.dtype)\n",
    "print(\"y batch shape:\", yb.shape, \"dtype:\", yb.dtype, \"classes in batch:\", yb.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012618bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionLabel(Enum):\n",
    "    WHITE_WINNING = 0\n",
    "    WHITE_DECISIVE = 1\n",
    "    WHITE_BETTER = 2\n",
    "    EQUAL = 3\n",
    "    BLACK_BETTER = 4\n",
    "    BLACK_DECISIVE = 5\n",
    "    BLACK_WINNING = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6db7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # bias = False because BatchNorm effectively cancels any bias term\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 =  nn.BatchNorm2d(channels)\n",
    "        self.bn2 =  nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.se = SEBlock(channels, reduction=8)\n",
    "        self.drop_path = DropPath(drop_prob) if drop_prob > 0. else nn.Identity()\n",
    "\n",
    "    # x is shape [19,8,8]\n",
    "    def forward(self, x):\n",
    "        identity = x \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.dropout(x) # adding causes val acc drop 15%\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.se(x)\n",
    "        x = self.drop_path(x)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        # x = self.dropout(x) # adding causes val acc drop 15%\n",
    "        return x\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        # Squeeze: Global Average Pooling (turns Cx8x8 tensor into Cx1x1 tensor (not flattened))\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Excitation: A tiny fully connected network to learn channel weights\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction), # Compress\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels), # Expand\n",
    "            nn.Sigmoid() # Output a (0.0 to 1.0) for importance\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, _, _ = x.size()\n",
    "        \n",
    "        # Calculate importance scores\n",
    "        y = self.avg_pool(x).view(batch, channels)\n",
    "        y = self.mlp(y).view(batch, channels, 1, 1)\n",
    "        \n",
    "        # Scale the original input by these scores\n",
    "        return x * y.expand_as(x)\n",
    "    \n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob: float = 0.):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0. or not self.training:\n",
    "            return x\n",
    "        \n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "\n",
    "        # Create a mask of 1s and 0s\n",
    "        random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "\n",
    "        # Apply mask and scale output to maintain expected value\n",
    "        return x.div(keep_prob) * random_tensor\n",
    "    \n",
    "class SEResNet(nn.Module):\n",
    "    def __init__(self, in_channels=19, channels=128, num_blocks=10, num_classes=7, drop_path_rate=0.2):\n",
    "        super().__init__()\n",
    "        # Initial convolution on board\n",
    "        self.initialconv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(start=0, end=drop_path_rate, steps=num_blocks)]\n",
    "\n",
    "        # Main residual block\n",
    "        blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            blocks.append(ResidualBlock(channels, drop_prob=dpr[i]))\n",
    "        self.res_tower = nn.Sequential(*blocks)\n",
    "\n",
    "\n",
    "        # Reduces channels to 32 before flattening\n",
    "        self.bottleneck_channels = 32\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(channels, self.bottleneck_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(self.bottleneck_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.flatten_dim = 64 * 8 * 8\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flatten_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)      \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initialconv(x)\n",
    "        x = self.res_tower(x)\n",
    "        # x = self.bottleneck(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a409f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               scaler: torch.amp.GradScaler,\n",
    "               device=device) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Performs one training epoch for the given model.\n",
    "    Returns the average loss and accuracy across all batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device) # X and Y are both shape (BATCH_SIZE,)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        with torch.amp.autocast(device):\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Update weights\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()  \n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy metrics\n",
    "        \"\"\"softmax and argmax dim=1 because tensor of shape (batchsize, num_classes)\"\"\"\n",
    "        y_pred_class = torch.argmax(y_pred, dim=-1) # y_pred_class.shape = (BATCH_SIZE,)\n",
    "        # train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "        # Remove for non prob ablation\n",
    "        y_true_class = torch.argmax(y, dim=-1)\n",
    "        train_acc += (y_pred_class == y_true_class).sum().item()/len(y_pred)\n",
    "        \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56112dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device=device) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the given model on the given dataloader without gradient updates.\n",
    "    Dataloader should either be the validation or test dataloader.\n",
    "    Returns the average loss and accuracy across all batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy metrics\n",
    "            test_pred_labels = torch.argmax(test_pred, dim=1)\n",
    "            # test_acc += (test_pred_labels == y).sum().item()/len(test_pred_labels)\n",
    "\n",
    "            # Remove for non prob ablation\n",
    "            y_true_labels = torch.argmax(y, dim=1)\n",
    "            test_acc += (test_pred_labels == y_true_labels).sum().item()/len(test_pred_labels)\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121015af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "def run_experiment(model: torch.nn.Module,\n",
    "                   model_save_name: str,\n",
    "                   train_dataloader: torch.utils.data.DataLoader,\n",
    "                   val_dataloader: torch.utils.data.DataLoader,\n",
    "                   loss_fn: torch.nn.Module,\n",
    "                   optimizer: torch.optim.Optimizer,\n",
    "                   scaler: torch.amp.GradScaler,\n",
    "                   epochs: int,\n",
    "                   patience: int,\n",
    "                   device=device):\n",
    "    \n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"val_acc\": []}\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0 \n",
    "    \n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer, mode='min', factor=0.1, patience=3\n",
    "    # )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=epochs,      \n",
    "        eta_min=1e-6         \n",
    "    )\n",
    "    \n",
    "    print(f\"Starting Training: {model_save_name}\")\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device,\n",
    "                                           scaler=scaler)\n",
    "        val_loss, val_acc = eval_step(model=model,\n",
    "                                      dataloader=val_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device)\n",
    "        \n",
    "        # scheduler.step(val_loss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_acc > best_val_acc: \n",
    "            best_val_acc = val_acc\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "            \n",
    "            print(f\"Epoch: {epoch} | New Best Val Acc: {val_acc:.4f} (Saved)\")\n",
    "            torch.save(model.state_dict(), f\"models/{model_save_name}.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Epoch: No improvement. Patience {patience_counter}/{patience}\")\n",
    "\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n[Early Stopping] No improvement for {patience} epochs. Stopping.\")\n",
    "            break \n",
    "\n",
    "    if best_model_weights is not None:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "        print(f\"\\nLoaded best model weights with Val Acc: {best_val_acc:.4f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34e1f957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "SEResNet                                      [512, 7]                  2,112\n",
       "Sequential: 1-1                             [512, 64, 8, 8]           --\n",
       "    Conv2d: 2-1                            [512, 64, 8, 8]           10,944\n",
       "    BatchNorm2d: 2-2                       [512, 64, 8, 8]           128\n",
       "    ReLU: 2-3                              [512, 64, 8, 8]           --\n",
       "Sequential: 1-2                             [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-4                     [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-1                       [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-2                  [512, 64, 8, 8]           128\n",
       "        ReLU: 3-3                         [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-4                       [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-5                  [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-6                      [512, 64, 8, 8]           1,096\n",
       "        Identity: 3-7                     [512, 64, 8, 8]           --\n",
       "        ReLU: 3-8                         [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-5                     [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-9                       [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-10                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-11                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-12                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-13                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-14                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-15                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-16                        [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-6                     [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-17                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-18                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-19                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-20                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-21                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-22                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-23                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-24                        [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-7                     [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-25                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-26                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-27                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-28                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-29                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-30                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-31                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-32                        [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-8                     [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-33                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-34                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-35                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-36                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-37                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-38                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-39                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-40                        [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-9                     [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-41                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-42                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-43                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-44                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-45                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-46                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-47                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-48                        [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-10                    [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-49                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-50                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-51                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-52                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-53                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-54                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-55                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-56                        [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-11                    [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-57                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-58                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-59                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-60                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-61                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-62                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-63                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-64                        [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-12                    [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-65                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-66                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-67                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-68                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-69                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-70                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-71                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-72                        [512, 64, 8, 8]           --\n",
       "    ResidualBlock: 2-13                    [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-73                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-74                 [512, 64, 8, 8]           128\n",
       "        ReLU: 3-75                        [512, 64, 8, 8]           --\n",
       "        Conv2d: 3-76                      [512, 64, 8, 8]           36,864\n",
       "        BatchNorm2d: 3-77                 [512, 64, 8, 8]           128\n",
       "        SEBlock: 3-78                     [512, 64, 8, 8]           1,096\n",
       "        DropPath: 3-79                    [512, 64, 8, 8]           --\n",
       "        ReLU: 3-80                        [512, 64, 8, 8]           --\n",
       "Sequential: 1-3                             [512, 7]                  --\n",
       "    Flatten: 2-14                          [512, 4096]               --\n",
       "    Linear: 2-15                           [512, 256]                1,048,832\n",
       "    ReLU: 2-16                             [512, 256]                --\n",
       "    Dropout: 2-17                          [512, 256]                --\n",
       "    Linear: 2-18                           [512, 7]                  1,799\n",
       "===============================================================================================\n",
       "Total params: 1,814,615\n",
       "Trainable params: 1,814,615\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 25.06\n",
       "===============================================================================================\n",
       "Input size (MB): 2.49\n",
       "Forward/backward pass size (MB): 708.67\n",
       "Params size (MB): 7.25\n",
       "Estimated Total Size (MB): 718.41\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = SEResNet(in_channels=19, \n",
    "                 channels=64, \n",
    "                 num_blocks=10, \n",
    "                 num_classes=7).to(device)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, 19, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be43b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training: probs_seresnet_droppath_c64_v10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [08:06<13:23:09, 486.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | New Best Val Acc: 0.5542 (Saved)\n",
      "Epoch: 0 | Train Loss: 1.3841 | Val Loss: 1.2794 | Val Acc: 0.5542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 2/100 [15:21<12:25:03, 456.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | New Best Val Acc: 0.5971 (Saved)\n",
      "Epoch: 1 | Train Loss: 1.2487 | Val Loss: 1.2122 | Val Acc: 0.5971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 3/100 [22:12<11:44:04, 435.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | New Best Val Acc: 0.6123 (Saved)\n",
      "Epoch: 2 | Train Loss: 1.2017 | Val Loss: 1.1893 | Val Acc: 0.6123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 4/100 [29:02<11:20:55, 425.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | New Best Val Acc: 0.6222 (Saved)\n",
      "Epoch: 3 | Train Loss: 1.1747 | Val Loss: 1.1739 | Val Acc: 0.6222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 5/100 [35:51<11:04:08, 419.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | New Best Val Acc: 0.6315 (Saved)\n",
      "Epoch: 4 | Train Loss: 1.1565 | Val Loss: 1.1627 | Val Acc: 0.6315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 6/100 [42:39<10:50:53, 415.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | New Best Val Acc: 0.6451 (Saved)\n",
      "Epoch: 5 | Train Loss: 1.1435 | Val Loss: 1.1380 | Val Acc: 0.6451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 7/100 [49:27<10:40:17, 413.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 6 | Train Loss: 1.1334 | Val Loss: 1.2067 | Val Acc: 0.6030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 8/100 [56:16<10:31:17, 411.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | New Best Val Acc: 0.6525 (Saved)\n",
      "Epoch: 7 | Train Loss: 1.1258 | Val Loss: 1.1280 | Val Acc: 0.6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 9/100 [1:04:04<10:51:12, 429.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 8 | Train Loss: 1.1193 | Val Loss: 1.1332 | Val Acc: 0.6518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 10/100 [1:10:50<10:33:06, 422.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 9 | Train Loss: 1.1136 | Val Loss: 1.1660 | Val Acc: 0.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 11/100 [1:17:36<10:18:57, 417.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | New Best Val Acc: 0.6612 (Saved)\n",
      "Epoch: 10 | Train Loss: 1.1092 | Val Loss: 1.1200 | Val Acc: 0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 12/100 [1:24:22<10:06:57, 413.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 11 | Train Loss: 1.1054 | Val Loss: 1.2794 | Val Acc: 0.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 13/100 [1:31:08<9:56:49, 411.60s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | New Best Val Acc: 0.6694 (Saved)\n",
      "Epoch: 12 | Train Loss: 1.1021 | Val Loss: 1.1093 | Val Acc: 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 14/100 [1:38:04<9:51:54, 412.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 13 | Train Loss: 1.0988 | Val Loss: 1.1257 | Val Acc: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 15/100 [1:45:26<9:57:23, 421.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | New Best Val Acc: 0.6717 (Saved)\n",
      "Epoch: 14 | Train Loss: 1.0960 | Val Loss: 1.1065 | Val Acc: 0.6717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 16/100 [1:52:12<9:43:29, 416.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 15 | Train Loss: 1.0938 | Val Loss: 1.1194 | Val Acc: 0.6576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 17/100 [1:59:01<9:33:21, 414.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 16 | Train Loss: 1.0913 | Val Loss: 1.1088 | Val Acc: 0.6666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 18/100 [2:05:46<9:22:44, 411.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | New Best Val Acc: 0.6740 (Saved)\n",
      "Epoch: 17 | Train Loss: 1.0894 | Val Loss: 1.0990 | Val Acc: 0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 19/100 [2:12:23<9:09:39, 407.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 18 | Train Loss: 1.0874 | Val Loss: 1.1016 | Val Acc: 0.6736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 20/100 [2:19:17<9:05:44, 409.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 19 | Train Loss: 1.0857 | Val Loss: 1.1242 | Val Acc: 0.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 21/100 [2:26:12<9:01:15, 411.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 20 | Train Loss: 1.0843 | Val Loss: 1.1251 | Val Acc: 0.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 22/100 [2:33:11<8:57:26, 413.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 4/101\n",
      "Epoch: 21 | Train Loss: 1.0826 | Val Loss: 1.1095 | Val Acc: 0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 23/100 [2:40:02<8:49:43, 412.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | New Best Val Acc: 0.6751 (Saved)\n",
      "Epoch: 22 | Train Loss: 1.0813 | Val Loss: 1.1030 | Val Acc: 0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 24/100 [2:46:51<8:41:10, 411.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 23 | Train Loss: 1.0799 | Val Loss: 1.1122 | Val Acc: 0.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 25/100 [2:53:40<8:33:22, 410.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | New Best Val Acc: 0.6778 (Saved)\n",
      "Epoch: 24 | Train Loss: 1.0785 | Val Loss: 1.0986 | Val Acc: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 26/100 [3:00:37<8:28:57, 412.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | New Best Val Acc: 0.6821 (Saved)\n",
      "Epoch: 25 | Train Loss: 1.0769 | Val Loss: 1.0959 | Val Acc: 0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 27/100 [3:07:34<8:23:50, 414.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 26 | Train Loss: 1.0760 | Val Loss: 1.0968 | Val Acc: 0.6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 28/100 [3:14:31<8:17:53, 414.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 27 | Train Loss: 1.0746 | Val Loss: 1.0994 | Val Acc: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 29/100 [3:21:50<8:19:24, 422.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 28 | Train Loss: 1.0733 | Val Loss: 1.1049 | Val Acc: 0.6714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 30/100 [3:29:05<8:16:47, 425.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 4/101\n",
      "Epoch: 29 | Train Loss: 1.0719 | Val Loss: 1.1323 | Val Acc: 0.6483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 31/100 [3:36:22<8:13:37, 429.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 5/101\n",
      "Epoch: 30 | Train Loss: 1.0709 | Val Loss: 1.0978 | Val Acc: 0.6756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 32/100 [3:43:53<8:13:55, 435.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 6/101\n",
      "Epoch: 31 | Train Loss: 1.0696 | Val Loss: 1.0927 | Val Acc: 0.6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 33/100 [3:51:48<8:19:45, 447.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 7/101\n",
      "Epoch: 32 | Train Loss: 1.0684 | Val Loss: 1.1201 | Val Acc: 0.6610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 34/100 [4:06:22<10:33:01, 575.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 8/101\n",
      "Epoch: 33 | Train Loss: 1.0674 | Val Loss: 1.0993 | Val Acc: 0.6779\n",
      "Epoch: 34 | New Best Val Acc: 0.6836 (Saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 35/100 [4:14:51<10:01:50, 555.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Train Loss: 1.0660 | Val Loss: 1.0930 | Val Acc: 0.6836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 36/100 [4:23:06<9:33:23, 537.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | New Best Val Acc: 0.6841 (Saved)\n",
      "Epoch: 35 | Train Loss: 1.0651 | Val Loss: 1.0911 | Val Acc: 0.6841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 37/100 [4:30:32<8:55:29, 509.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 36 | Train Loss: 1.0638 | Val Loss: 1.1011 | Val Acc: 0.6724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 38/100 [4:37:21<8:15:47, 479.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 37 | Train Loss: 1.0626 | Val Loss: 1.0973 | Val Acc: 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 39/100 [4:44:09<7:45:37, 457.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 38 | Train Loss: 1.0614 | Val Loss: 1.1361 | Val Acc: 0.6556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 40/100 [4:50:56<7:22:56, 442.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 4/101\n",
      "Epoch: 39 | Train Loss: 1.0602 | Val Loss: 1.1069 | Val Acc: 0.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 41/100 [4:57:39<7:03:48, 430.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 5/101\n",
      "Epoch: 40 | Train Loss: 1.0590 | Val Loss: 1.1145 | Val Acc: 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 42/100 [5:04:37<6:52:45, 426.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | New Best Val Acc: 0.6869 (Saved)\n",
      "Epoch: 41 | Train Loss: 1.0579 | Val Loss: 1.0891 | Val Acc: 0.6869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 43/100 [5:11:34<6:42:40, 423.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | New Best Val Acc: 0.6878 (Saved)\n",
      "Epoch: 42 | Train Loss: 1.0566 | Val Loss: 1.0896 | Val Acc: 0.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 44/100 [5:18:15<6:29:09, 416.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 43 | Train Loss: 1.0553 | Val Loss: 1.0941 | Val Acc: 0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 45/100 [5:25:15<6:23:07, 417.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 44 | Train Loss: 1.0542 | Val Loss: 1.0895 | Val Acc: 0.6858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 46/100 [5:34:47<6:57:52, 464.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 45 | Train Loss: 1.0528 | Val Loss: 1.0888 | Val Acc: 0.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 47/100 [5:43:44<7:09:11, 485.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 4/101\n",
      "Epoch: 46 | Train Loss: 1.0517 | Val Loss: 1.0970 | Val Acc: 0.6814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 48/100 [5:52:10<7:06:27, 492.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 5/101\n",
      "Epoch: 47 | Train Loss: 1.0505 | Val Loss: 1.0980 | Val Acc: 0.6804\n",
      "Epoch: 48 | New Best Val Acc: 0.6881 (Saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 49/100 [6:00:43<7:03:38, 498.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Train Loss: 1.0491 | Val Loss: 1.0891 | Val Acc: 0.6881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 50/100 [6:08:39<6:49:46, 491.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 49 | Train Loss: 1.0479 | Val Loss: 1.1069 | Val Acc: 0.6754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 51/100 [6:16:11<6:31:43, 479.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 50 | Train Loss: 1.0467 | Val Loss: 1.0902 | Val Acc: 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 52/100 [6:23:42<6:16:56, 471.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 51 | Train Loss: 1.0455 | Val Loss: 1.1087 | Val Acc: 0.6714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 53/100 [6:30:54<5:59:45, 459.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 | New Best Val Acc: 0.6887 (Saved)\n",
      "Epoch: 52 | Train Loss: 1.0440 | Val Loss: 1.0869 | Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 54/100 [6:37:49<5:42:04, 446.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 53 | Train Loss: 1.0426 | Val Loss: 1.0937 | Val Acc: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 55/100 [6:44:44<5:27:31, 436.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 54 | Train Loss: 1.0414 | Val Loss: 1.0932 | Val Acc: 0.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 56/100 [6:51:34<5:14:26, 428.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 55 | Train Loss: 1.0400 | Val Loss: 1.0949 | Val Acc: 0.6856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 57/100 [6:58:28<5:03:59, 424.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 | New Best Val Acc: 0.6892 (Saved)\n",
      "Epoch: 56 | Train Loss: 1.0387 | Val Loss: 1.0882 | Val Acc: 0.6892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 58/100 [7:06:31<5:09:14, 441.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 57 | Train Loss: 1.0371 | Val Loss: 1.0924 | Val Acc: 0.6872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 59/100 [7:15:18<5:19:28, 467.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 58 | Train Loss: 1.0356 | Val Loss: 1.0917 | Val Acc: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 60/100 [7:22:10<5:00:34, 450.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 59 | Train Loss: 1.0342 | Val Loss: 1.0942 | Val Acc: 0.6858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 61/100 [7:28:59<4:44:54, 438.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | New Best Val Acc: 0.6893 (Saved)\n",
      "Epoch: 60 | Train Loss: 1.0328 | Val Loss: 1.0938 | Val Acc: 0.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 62/100 [7:35:52<4:32:41, 430.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 61 | Train Loss: 1.0312 | Val Loss: 1.0993 | Val Acc: 0.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 63/100 [7:42:45<4:22:20, 425.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 | New Best Val Acc: 0.6900 (Saved)\n",
      "Epoch: 62 | Train Loss: 1.0298 | Val Loss: 1.0910 | Val Acc: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 64/100 [7:49:53<4:15:38, 426.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 | New Best Val Acc: 0.6916 (Saved)\n",
      "Epoch: 63 | Train Loss: 1.0281 | Val Loss: 1.0872 | Val Acc: 0.6916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 65/100 [7:57:01<4:08:56, 426.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 64 | Train Loss: 1.0268 | Val Loss: 1.0900 | Val Acc: 0.6902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 66/100 [8:06:42<4:27:59, 472.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 65 | Train Loss: 1.0252 | Val Loss: 1.1049 | Val Acc: 0.6808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 67/100 [8:14:23<4:18:11, 469.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 66 | Train Loss: 1.0237 | Val Loss: 1.0990 | Val Acc: 0.6839\n",
      "Epoch: 67 | New Best Val Acc: 0.6926 (Saved)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 68/100 [8:22:02<4:08:45, 466.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 | Train Loss: 1.0221 | Val Loss: 1.0914 | Val Acc: 0.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 69/100 [8:29:03<3:53:51, 452.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 68 | Train Loss: 1.0203 | Val Loss: 1.0934 | Val Acc: 0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 70/100 [8:36:01<3:41:13, 442.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 69 | Train Loss: 1.0188 | Val Loss: 1.0908 | Val Acc: 0.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 71/100 [8:43:29<3:34:32, 443.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 70 | Train Loss: 1.0172 | Val Loss: 1.0956 | Val Acc: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 72/100 [8:51:27<3:32:01, 454.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 4/101\n",
      "Epoch: 71 | Train Loss: 1.0156 | Val Loss: 1.0942 | Val Acc: 0.6920\n",
      "Epoch: 72 | New Best Val Acc: 0.6928 (Saved)\n",
      "Epoch: 72 | Train Loss: 1.0140 | Val Loss: 1.0953 | Val Acc: 0.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 74/100 [9:07:54<3:26:59, 477.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 73 | Train Loss: 1.0123 | Val Loss: 1.0944 | Val Acc: 0.6926\n",
      "Epoch: 74 | New Best Val Acc: 0.6945 (Saved)\n",
      "Epoch: 74 | Train Loss: 1.0106 | Val Loss: 1.0952 | Val Acc: 0.6945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 76/100 [9:22:55<3:05:25, 463.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 75 | Train Loss: 1.0092 | Val Loss: 1.0980 | Val Acc: 0.6920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 77/100 [9:30:13<2:54:46, 455.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 76 | Train Loss: 1.0077 | Val Loss: 1.0978 | Val Acc: 0.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 78/100 [9:37:57<2:48:02, 458.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 77 | Train Loss: 1.0061 | Val Loss: 1.0979 | Val Acc: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 79/100 [9:45:04<2:37:07, 448.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 4/101\n",
      "Epoch: 78 | Train Loss: 1.0046 | Val Loss: 1.0976 | Val Acc: 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 80/100 [9:51:57<2:26:01, 438.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 5/101\n",
      "Epoch: 79 | Train Loss: 1.0031 | Val Loss: 1.1037 | Val Acc: 0.6920\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(),\n",
    "                              lr=0.001,\n",
    "                              weight_decay=0.01)\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "result = run_experiment(model=model,\n",
    "                        model_save_name=model_save_name,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        scaler=scaler,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        patience=NUM_EPOCHS + 1,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23488d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_to_index = {\"P\":0,\n",
    "                  \"N\":1,\n",
    "                  \"B\":2,\n",
    "                  \"R\":3,\n",
    "                  \"Q\":4,\n",
    "                  \"K\":5,\n",
    "                  \"p\":6,\n",
    "                  \"n\":7,\n",
    "                  \"b\":8,\n",
    "                  \"r\":9,\n",
    "                  \"q\":10,\n",
    "                  \"k\":11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d13910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_tensor(fen):\n",
    "    \"\"\"\n",
    "    Converts FEN into a (19, 8, 8) tensor.\n",
    "    \"\"\"\n",
    "    board = chess.Board(fen)\n",
    "    tensor = np.zeros((19, 8, 8), dtype=np.uint8)\n",
    "\n",
    "    piece_to_channel = {\n",
    "        \"P\": 0, \"N\": 1, \"B\": 2, \"R\": 3, \"Q\": 4, \"K\": 5,\n",
    "        \"p\": 6, \"n\": 7, \"b\": 8, \"r\": 9, \"q\": 10, \"k\": 11\n",
    "    }\n",
    "\n",
    "    for square, piece in board.piece_map().items():\n",
    "        channel = piece_to_channel[piece.symbol()]\n",
    "        row, col = divmod(square, 8)\n",
    "        tensor[channel, row, col] = 1\n",
    "\n",
    "    \n",
    "    if board.turn == chess.WHITE:\n",
    "        tensor[12, :, :] = 1\n",
    "    if board.has_kingside_castling_rights(chess.WHITE):\n",
    "        tensor[13, :, :] = 1\n",
    "    if board.has_queenside_castling_rights(chess.WHITE):\n",
    "        tensor[14, :, :] = 1\n",
    "    if board.has_kingside_castling_rights(chess.BLACK):\n",
    "        tensor[15, :, :] = 1\n",
    "    if board.has_queenside_castling_rights(chess.BLACK):\n",
    "        tensor[16, :, :] = 1\n",
    "    if board.is_check():\n",
    "        tensor[17, :, :] = 1\n",
    "\n",
    "    if board.ep_square is not None:\n",
    "        row, col = divmod(board.ep_square, 8)\n",
    "        tensor[18, row, col] = 1\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e936bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction:  5\n",
      "Stockfish Evaluation:  5\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r . . . k b . r\n",
       "p . . b . p p .\n",
       ". . p . p q . p\n",
       "P . . n . . . .\n",
       ". . . P . . . .\n",
       ". Q . . . N . .\n",
       ". P P . . P P P\n",
       "R . B . . R K .</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(240, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(285, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(60, 240)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(240, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 150)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(150, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 105)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(240, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(150, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
      ],
      "text/plain": [
       "Board('r3kb1r/p2b1pp1/2p1pq1p/P2n4/3P4/1Q3N2/1PP2PPP/R1B2RK1 b kq - 2 14')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_model_prediction(model: torch.nn.Module,\n",
    "                           random_fen: str,\n",
    "                           fen_class: int,\n",
    "                           device=device):\n",
    "    \"\"\"Takes the given fen to see the board, predicted score and actual score\"\"\"\n",
    "\n",
    "    numpy_fen = fen_to_tensor(random_fen)\n",
    "    torch_fen = torch.tensor(numpy_fen, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    pred = torch.argmax(model(torch_fen), dim=-1)\n",
    "    print(\"Model Prediction: \", pred.item())\n",
    "    print(\"Stockfish Evaluation: \", fen_class)\n",
    "\n",
    "# Remember to update fen_class manually\n",
    "random_fen = \"r3kb1r/p2b1pp1/2p1pq1p/P2n4/3P4/1Q3N2/1PP2PPP/R1B2RK1 b kq - 2 14\"\n",
    "check_model_prediction(model=model,\n",
    "                       random_fen=random_fen,\n",
    "                       fen_class=5, # remember to manually set \n",
    "                       device=device)\n",
    "\n",
    "board = chess.Board(random_fen)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82     85756\n",
      "           1       0.65      0.64      0.65     85446\n",
      "           2       0.64      0.64      0.64     85601\n",
      "           3       0.62      0.68      0.65     86225\n",
      "           4       0.66      0.65      0.65     85229\n",
      "           5       0.66      0.63      0.65     85573\n",
      "           6       0.83      0.82      0.82     85377\n",
      "\n",
      "    accuracy                           0.70    599207\n",
      "   macro avg       0.70      0.70      0.70    599207\n",
      "weighted avg       0.70      0.70      0.70    599207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in val_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X).argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        # all_labels.extend(y.cpu().numpy())\n",
    "        true_labels = y.argmax(dim=1) \n",
    "        all_labels.extend(true_labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efa820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "LOGS_DIR = f\"experiments/logs/{model_save_name}\"\n",
    "\n",
    "def save_config_metadata(experiment_name: str, \n",
    "                         model: torch.nn.Module, \n",
    "                         hyperparams: dict, \n",
    "                         dataset_paths: dict,\n",
    "                         save_dir: str = LOGS_DIR):\n",
    "    \"\"\"\n",
    "    Saves all 'static' setup details: Model architecture, parameter counts, \n",
    "    datasets used, and hyperparameters.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Model Metadata\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    config_data = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_architecture\": {\n",
    "            \"class_name\": model.__class__.__name__,\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"input_dim\": hyperparams.get(\"input_shape\", \"unknown\"),\n",
    "            \"output_dim\": hyperparams.get(\"output_shape\", \"unknown\"),\n",
    "            \"structure_summary\": str(model)\n",
    "        },\n",
    "        \"datasets\": dataset_paths,\n",
    "        \"hyperparameters\": hyperparams,\n",
    "        \"device\": torch.cuda.get_device_name() if torch.cuda.is_available() else \"cpu\"\n",
    "    }\n",
    "\n",
    "    file_path = f\"{save_dir}/{experiment_name}_config.json\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(config_data, f, indent=4)\n",
    "    \n",
    "    print(f\"[Config] Saved metadata to {file_path}\")\n",
    "    \n",
    "def save_training_logs(experiment_name: str, \n",
    "                       results_dict: dict, \n",
    "                       save_dir: str = LOGS_DIR):\n",
    "    \"\"\"\n",
    "    Saves the epoch-by-epoch learning curves (Loss/Acc) to CSV.\n",
    "    Expects results_dict to be the output from your run_experiment function.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df = pd.DataFrame(results_dict)\n",
    "    \n",
    "    if \"epoch\" not in df.columns:\n",
    "        df[\"epoch\"] = range(1, len(df) + 1)\n",
    "        \n",
    "    file_path = f\"{save_dir}/{experiment_name}_learning_curves.csv\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"[Logs] Saved training history to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "RESULTS_DIR = f\"experiments/results/{model_save_name}\"\n",
    "\n",
    "def calculate_ordinal_metrics(preds: np.ndarray,\n",
    "                              labels: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculates metrics specific to ordinal classification (where Class 0 is close to Class 1).\n",
    "    \"\"\"\n",
    "    abs_diffs = np.abs(preds - labels)\n",
    "    \n",
    "    metrics = {\n",
    "        \"mae\": float(np.mean(abs_diffs)),\n",
    "        \"off_by_one_accuracy\": float(np.mean(abs_diffs <= 1)),\n",
    "        \"off_by_two_accuracy\": float(np.mean(abs_diffs <= 2))\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def categorize_failures(preds: np.ndarray, \n",
    "                        labels: np.ndarray) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    Categorizes errors by magnitude.\n",
    "    Returns a dict where keys are the error magnitude (3, 4, 5, 6) and values are lists of dataset indices.\n",
    "    \"\"\"\n",
    "    abs_diffs = np.abs(preds - labels)\n",
    "    failure_dict = {}\n",
    "    \n",
    "    # We care about errors >= 3 (e.g. Predicting 'Equal' when 'Black Winning')\n",
    "    # Max error is 6 (Predicting 'White Winning' when 'Black Winning')\n",
    "    for magnitude in range(3, 7):\n",
    "        indices = np.where(abs_diffs == magnitude)[0].tolist()\n",
    "        if indices:\n",
    "            failure_dict[magnitude] = indices\n",
    "            \n",
    "    return failure_dict\n",
    "\n",
    "def run_inference(model: torch.nn.Module, \n",
    "                  dataloader: torch.utils.data.DataLoader, \n",
    "                  device: str) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Runs inference and tracks latency. Returns predictions, true labels, and avg latency per sample (ms).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            # all_labels.extend(y.cpu().numpy())\n",
    "            true_labels = y.argmax(dim=1) \n",
    "            all_labels.extend(true_labels.cpu().numpy())\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    num_samples = len(all_labels)\n",
    "    avg_latency_ms = (total_time / num_samples) * 1000\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), avg_latency_ms\n",
    "\n",
    "def save_test_results(experiment_name: str, \n",
    "                      model: torch.nn.Module, \n",
    "                      test_dataloader: torch.utils.data.DataLoader, \n",
    "                      device: str,\n",
    "                      save_dir: str = RESULTS_DIR):\n",
    "    \"\"\"\n",
    "    Orchestrates the testing process and saves all research-grade metrics.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    preds, labels, latency_ms = run_inference(model, test_dataloader, device)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    class_report = classification_report(labels, preds, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    ordinal_metrics = calculate_ordinal_metrics(preds, labels)\n",
    "    failure_indices = categorize_failures(preds, labels)\n",
    "    \n",
    "    final_metrics = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"global_accuracy\": acc,\n",
    "        \"inference_latency_ms\": latency_ms,\n",
    "        \"ordinal_metrics\": ordinal_metrics,\n",
    "        \"catastrophic_failure_counts\": {k: len(v) for k, v in failure_indices.items()},\n",
    "        \"classification_report\": class_report\n",
    "    }\n",
    "\n",
    "    json_path = f\"{save_dir}/{experiment_name}_metrics.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(final_metrics, f, indent=4)\n",
    "        \n",
    "    npy_path = f\"{save_dir}/{experiment_name}_confusion_matrix.npy\"\n",
    "    np.save(npy_path, conf_matrix)\n",
    "    \n",
    "    # Failure Indices JSON (for later visual analysis of specific FENs)\n",
    "    failures_path = f\"{save_dir}/{experiment_name}_failure_indices.json\"\n",
    "    with open(failures_path, \"w\") as f:\n",
    "        json.dump(failure_indices, f)\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"[Results] Accuracy:        {acc*100:.2f}%\")\n",
    "    print(f\"[Results] Off-by-1 Acc:    {ordinal_metrics['off_by_one_accuracy']*100:.2f}%\")\n",
    "    print(f\"[Results] MAE:             {ordinal_metrics['mae']:.4f}\")\n",
    "    print(f\"[Results] Latency:         {latency_ms:.4f} ms/sample\")\n",
    "    print(\"[Results] Catastrophic Failures (Count):\")\n",
    "    for k in sorted(failure_indices.keys()):\n",
    "        print(f\"   - Off by {k}: {len(failure_indices[k])} samples\")\n",
    "    print(f\"[Results] Saved all metrics to {save_dir}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed637bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Config] Saved metadata to experiments/logs/probs_seresnet_droppath_c64_bn_v9/run_2026_01_15_probs_seresnet_droppath_c64_bn_v9_config.json\n",
      "[Logs] Saved training history to experiments/logs/probs_seresnet_droppath_c64_bn_v9/run_2026_01_15_probs_seresnet_droppath_c64_bn_v9_learning_curves.csv\n",
      "------------------------------------------------------------\n",
      "[Results] Accuracy:        69.37%\n",
      "[Results] Off-by-1 Acc:    94.87%\n",
      "[Results] MAE:             0.3850\n",
      "[Results] Latency:         0.1077 ms/sample\n",
      "[Results] Catastrophic Failures (Count):\n",
      "   - Off by 3: 7824 samples\n",
      "   - Off by 4: 1827 samples\n",
      "   - Off by 5: 980 samples\n",
      "   - Off by 6: 459 samples\n",
      "[Results] Saved all metrics to experiments/results/probs_seresnet_droppath_c64_bn_v9\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"input_shape\": 775,\n",
    "    \"output_shape\": 7\n",
    "}\n",
    "\n",
    "dataset_paths = {\n",
    "    \"train\": str(TRAIN_PATH),\n",
    "    \"val\":   str(VAL_PATH),\n",
    "    \"test\":  str(TEST_PATH)\n",
    "}\n",
    "\n",
    "save_config_metadata(experiment_name=RUN_ID,\n",
    "                     model=model,\n",
    "                     hyperparams=hyperparams,\n",
    "                     dataset_paths=dataset_paths)\n",
    "\n",
    "# Save Training Logs (Using the 'result' variable from run_experiment)\n",
    "save_training_logs(experiment_name=RUN_ID, \n",
    "                   results_dict=result)\n",
    "\n",
    "save_test_results(experiment_name=RUN_ID,\n",
    "                  model=model,\n",
    "                  test_dataloader=test_dataloader,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b3fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = Path(f\"./experiments/logs/{model_save_name}/{RUN_ID}_learning_curves.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Val Loss', color='orange')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df['epoch'], df['train_acc'], label='Train Accuracy', color='blue')\n",
    "plt.plot(df['epoch'], df['val_acc'], label='Val Accuracy', color='orange')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e14216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessenv",
   "language": "python",
   "name": "chessenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
