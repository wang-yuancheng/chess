{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b389472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import chess\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU:\", torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"run_2026_01_15_probs_seresnet_droppath_c128_bn_v8\"\n",
    "model_save_name = \"probs_seresnet_droppath_c128_bn_v8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39910bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPZChessDataset(Dataset):\n",
    "    def __init__(self, npz_path: Path):\n",
    "        with np.load(npz_path) as data:\n",
    "            self.X = torch.tensor(data[\"X\"], dtype=torch.float32) # float32 for NNs\n",
    "            self.y = torch.tensor(data[\"y\"], dtype=torch.long) # long for CrossEntropyLoss\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "num_workers = 0\n",
    "\n",
    "TRAIN_PATH = Path(\"./dataset_planes/plane_train.npz\")\n",
    "VAL_PATH = Path(\"./dataset_planes/plane_val.npz\")\n",
    "TEST_PATH = Path(\"./dataset_planes/plane_test.npz\") \n",
    "\n",
    "train_dataloader = DataLoader(dataset=NPZChessDataset(TRAIN_PATH), \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True)\n",
    "val_dataloader = DataLoader(dataset=NPZChessDataset(VAL_PATH), \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            num_workers=num_workers,\n",
    "                            shuffle=False,\n",
    "                            pin_memory=True)\n",
    "test_dataloader = DataLoader(dataset=NPZChessDataset(TEST_PATH), \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             num_workers=num_workers,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for i, (X, y) in enumerate(train_dataloader):\n",
    "    if i == 100:  # measure 100 batches\n",
    "        break\n",
    "print(\"Avg batch load time:\", (time.time() - start) / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5bdf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb, yb = next(iter(train_dataloader))\n",
    "print(\"X batch shape:\", Xb.shape, \"dtype:\", Xb.dtype)\n",
    "print(\"y batch shape:\", yb.shape, \"dtype:\", yb.dtype, \"classes in batch:\", yb.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012618bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionLabel(Enum):\n",
    "    WHITE_WINNING = 0\n",
    "    WHITE_DECISIVE = 1\n",
    "    WHITE_BETTER = 2\n",
    "    EQUAL = 3\n",
    "    BLACK_BETTER = 4\n",
    "    BLACK_DECISIVE = 5\n",
    "    BLACK_WINNING = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # bias = False because BatchNorm effectively cancels any bias term\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 =  nn.BatchNorm2d(channels)\n",
    "        self.bn2 =  nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.se = SEBlock(channels, reduction=8)\n",
    "        self.drop_path = DropPath(drop_prob) if drop_prob > 0. else nn.Identity()\n",
    "\n",
    "    # x is shape [19,8,8]\n",
    "    def forward(self, x):\n",
    "        identity = x \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.dropout(x) # adding causes val acc drop 15%\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.se(x)\n",
    "        x = self.drop_path(x)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        # x = self.dropout(x) # adding causes val acc drop 15%\n",
    "        return x\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        # Squeeze: Global Average Pooling (turns Cx8x8 tensor into Cx1x1 tensor (not flattened))\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Excitation: A tiny fully connected network to learn channel weights\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction), # Compress\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels), # Expand\n",
    "            nn.Sigmoid() # Output a (0.0 to 1.0) for importance\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, _, _ = x.size()\n",
    "        \n",
    "        # Calculate importance scores\n",
    "        y = self.avg_pool(x).view(batch, channels)\n",
    "        y = self.mlp(y).view(batch, channels, 1, 1)\n",
    "        \n",
    "        # Scale the original input by these scores\n",
    "        return x * y.expand_as(x)\n",
    "    \n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob: float = 0.):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0. or not self.training:\n",
    "            return x\n",
    "        \n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "\n",
    "        # Create a mask of 1s and 0s\n",
    "        random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "\n",
    "        # Apply mask and scale output to maintain expected value\n",
    "        return x.div(keep_prob) * random_tensor\n",
    "    \n",
    "class SEResNet(nn.Module):\n",
    "    def __init__(self, in_channels=19, channels=128, num_blocks=10, num_classes=7, drop_path_rate=0.2):\n",
    "        super().__init__()\n",
    "        # Initial convolution on board\n",
    "        self.initialconv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(start=0, end=drop_path_rate, steps=num_blocks)]\n",
    "\n",
    "        # Main residual block\n",
    "        blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            blocks.append(ResidualBlock(channels, drop_prob=dpr[i]))\n",
    "        self.res_tower = nn.Sequential(*blocks)\n",
    "\n",
    "\n",
    "        # Reduces channels from 128 -> 32 before flattening\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.flatten_dim = self.bottleneck_channels * 8 * 8\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flatten_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)      \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initialconv(x)\n",
    "        x = self.res_tower(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               scaler: torch.amp.GradScaler,\n",
    "               device=device) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Performs one training epoch for the given model.\n",
    "    Returns the average loss and accuracy across all batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device) # X and Y are both shape (BATCH_SIZE,)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        with torch.amp.autocast(device):\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Update weights\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()  \n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy metrics\n",
    "        \"\"\"softmax and argmax dim=1 because tensor of shape (batchsize, num_classes)\"\"\"\n",
    "        y_pred_class = torch.argmax(y_pred, dim=-1) # y_pred_class.shape = (BATCH_SIZE,)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56112dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device=device) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the given model on the given dataloader without gradient updates.\n",
    "    Dataloader should either be the validation or test dataloader.\n",
    "    Returns the average loss and accuracy across all batches.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy metrics\n",
    "            test_pred_labels = torch.argmax(test_pred, dim=1)\n",
    "            test_acc += (test_pred_labels == y).sum().item()/len(test_pred_labels)\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121015af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "def run_experiment(model: torch.nn.Module,\n",
    "                   model_save_name: str,\n",
    "                   train_dataloader: torch.utils.data.DataLoader,\n",
    "                   val_dataloader: torch.utils.data.DataLoader,\n",
    "                   loss_fn: torch.nn.Module,\n",
    "                   optimizer: torch.optim.Optimizer,\n",
    "                   scaler: torch.amp.GradScaler,\n",
    "                   epochs: int,\n",
    "                   patience: int,\n",
    "                   device=device):\n",
    "    \n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"val_acc\": []}\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0 \n",
    "    \n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer, mode='min', factor=0.1, patience=3\n",
    "    # )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=epochs,      \n",
    "        eta_min=1e-6         \n",
    "    )\n",
    "    \n",
    "    print(f\"Starting Training: {model_save_name}\")\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device,\n",
    "                                           scaler=scaler)\n",
    "        val_loss, val_acc = eval_step(model=model,\n",
    "                                      dataloader=val_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device)\n",
    "        \n",
    "        # scheduler.step(val_loss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_acc > best_val_acc: \n",
    "            best_val_acc = val_acc\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "            \n",
    "            print(f\"Epoch {epoch}: New Best Val Acc: {val_acc:.4f} (Saved)\")\n",
    "            torch.save(model.state_dict(), f\"models/{model_save_name}.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Epoch {epoch}: No improvement. Patience {patience_counter}/{patience}\")\n",
    "\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n[Early Stopping] No improvement for {patience} epochs. Stopping.\")\n",
    "            break \n",
    "\n",
    "    if best_model_weights is not None:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "        print(f\"\\nLoaded best model weights with Val Acc: {best_val_acc:.4f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = SEResNet(in_channels=19, \n",
    "                 channels=128, \n",
    "                 num_blocks=10, \n",
    "                 num_classes=7).to(device)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, 19, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(),\n",
    "                              lr=0.001,\n",
    "                              weight_decay=0.01)\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "result = run_experiment(model=model,\n",
    "                        model_save_name=model_save_name,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        scaler=scaler,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        patience=NUM_EPOCHS + 1,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23488d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_to_index = {\"P\":0,\n",
    "                  \"N\":1,\n",
    "                  \"B\":2,\n",
    "                  \"R\":3,\n",
    "                  \"Q\":4,\n",
    "                  \"K\":5,\n",
    "                  \"p\":6,\n",
    "                  \"n\":7,\n",
    "                  \"b\":8,\n",
    "                  \"r\":9,\n",
    "                  \"q\":10,\n",
    "                  \"k\":11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d13910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_tensor(fen):\n",
    "    \"\"\"\n",
    "    Converts FEN into a (19, 8, 8) tensor.\n",
    "    \"\"\"\n",
    "    board = chess.Board(fen)\n",
    "    tensor = np.zeros((19, 8, 8), dtype=np.uint8)\n",
    "\n",
    "    piece_to_channel = {\n",
    "        \"P\": 0, \"N\": 1, \"B\": 2, \"R\": 3, \"Q\": 4, \"K\": 5,\n",
    "        \"p\": 6, \"n\": 7, \"b\": 8, \"r\": 9, \"q\": 10, \"k\": 11\n",
    "    }\n",
    "\n",
    "    for square, piece in board.piece_map().items():\n",
    "        channel = piece_to_channel[piece.symbol()]\n",
    "        row, col = divmod(square, 8)\n",
    "        tensor[channel, row, col] = 1\n",
    "\n",
    "    \n",
    "    if board.turn == chess.WHITE:\n",
    "        tensor[12, :, :] = 1\n",
    "    if board.has_kingside_castling_rights(chess.WHITE):\n",
    "        tensor[13, :, :] = 1\n",
    "    if board.has_queenside_castling_rights(chess.WHITE):\n",
    "        tensor[14, :, :] = 1\n",
    "    if board.has_kingside_castling_rights(chess.BLACK):\n",
    "        tensor[15, :, :] = 1\n",
    "    if board.has_queenside_castling_rights(chess.BLACK):\n",
    "        tensor[16, :, :] = 1\n",
    "    if board.is_check():\n",
    "        tensor[17, :, :] = 1\n",
    "\n",
    "    if board.ep_square is not None:\n",
    "        row, col = divmod(board.ep_square, 8)\n",
    "        tensor[18, row, col] = 1\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e936bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_prediction(model: torch.nn.Module,\n",
    "                           random_fen: str,\n",
    "                           fen_class: int,\n",
    "                           device=device):\n",
    "    \"\"\"Takes the given fen to see the board, predicted score and actual score\"\"\"\n",
    "\n",
    "    numpy_fen = fen_to_tensor(random_fen)\n",
    "    torch_fen = torch.tensor(numpy_fen, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    pred = torch.argmax(model(torch_fen), dim=-1)\n",
    "    print(\"Model Prediction: \", pred.item())\n",
    "    print(\"Stockfish Evaluation: \", fen_class)\n",
    "\n",
    "# Remember to update fen_class manually\n",
    "random_fen = \"r3kb1r/p2b1pp1/2p1pq1p/P2n4/3P4/1Q3N2/1PP2PPP/R1B2RK1 b kq - 2 14\"\n",
    "check_model_prediction(model=model,\n",
    "                       random_fen=random_fen,\n",
    "                       fen_class=5, # remember to manually set \n",
    "                       device=device)\n",
    "\n",
    "board = chess.Board(random_fen)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in val_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X).argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efa820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "LOGS_DIR = f\"experiments/logs/{model_save_name}\"\n",
    "\n",
    "def save_config_metadata(experiment_name: str, \n",
    "                         model: torch.nn.Module, \n",
    "                         hyperparams: dict, \n",
    "                         dataset_paths: dict,\n",
    "                         save_dir: str = LOGS_DIR):\n",
    "    \"\"\"\n",
    "    Saves all 'static' setup details: Model architecture, parameter counts, \n",
    "    datasets used, and hyperparameters.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Model Metadata\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    config_data = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_architecture\": {\n",
    "            \"class_name\": model.__class__.__name__,\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"input_dim\": hyperparams.get(\"input_shape\", \"unknown\"),\n",
    "            \"output_dim\": hyperparams.get(\"output_shape\", \"unknown\"),\n",
    "            \"structure_summary\": str(model)\n",
    "        },\n",
    "        \"datasets\": dataset_paths,\n",
    "        \"hyperparameters\": hyperparams,\n",
    "        \"device\": torch.cuda.get_device_name() if torch.cuda.is_available() else \"cpu\"\n",
    "    }\n",
    "\n",
    "    file_path = f\"{save_dir}/{experiment_name}_config.json\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(config_data, f, indent=4)\n",
    "    \n",
    "    print(f\"[Config] Saved metadata to {file_path}\")\n",
    "    \n",
    "def save_training_logs(experiment_name: str, \n",
    "                       results_dict: dict, \n",
    "                       save_dir: str = LOGS_DIR):\n",
    "    \"\"\"\n",
    "    Saves the epoch-by-epoch learning curves (Loss/Acc) to CSV.\n",
    "    Expects results_dict to be the output from your run_experiment function.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df = pd.DataFrame(results_dict)\n",
    "    \n",
    "    if \"epoch\" not in df.columns:\n",
    "        df[\"epoch\"] = range(1, len(df) + 1)\n",
    "        \n",
    "    file_path = f\"{save_dir}/{experiment_name}_learning_curves.csv\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"[Logs] Saved training history to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "RESULTS_DIR = f\"experiments/results/{model_save_name}\"\n",
    "\n",
    "def calculate_ordinal_metrics(preds: np.ndarray,\n",
    "                              labels: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculates metrics specific to ordinal classification (where Class 0 is close to Class 1).\n",
    "    \"\"\"\n",
    "    abs_diffs = np.abs(preds - labels)\n",
    "    \n",
    "    metrics = {\n",
    "        \"mae\": float(np.mean(abs_diffs)),\n",
    "        \"off_by_one_accuracy\": float(np.mean(abs_diffs <= 1)),\n",
    "        \"off_by_two_accuracy\": float(np.mean(abs_diffs <= 2))\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def categorize_failures(preds: np.ndarray, \n",
    "                        labels: np.ndarray) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    Categorizes errors by magnitude.\n",
    "    Returns a dict where keys are the error magnitude (3, 4, 5, 6) and values are lists of dataset indices.\n",
    "    \"\"\"\n",
    "    abs_diffs = np.abs(preds - labels)\n",
    "    failure_dict = {}\n",
    "    \n",
    "    # We care about errors >= 3 (e.g. Predicting 'Equal' when 'Black Winning')\n",
    "    # Max error is 6 (Predicting 'White Winning' when 'Black Winning')\n",
    "    for magnitude in range(3, 7):\n",
    "        indices = np.where(abs_diffs == magnitude)[0].tolist()\n",
    "        if indices:\n",
    "            failure_dict[magnitude] = indices\n",
    "            \n",
    "    return failure_dict\n",
    "\n",
    "def run_inference(model: torch.nn.Module, \n",
    "                  dataloader: torch.utils.data.DataLoader, \n",
    "                  device: str) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Runs inference and tracks latency. Returns predictions, true labels, and avg latency per sample (ms).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    num_samples = len(all_labels)\n",
    "    avg_latency_ms = (total_time / num_samples) * 1000\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), avg_latency_ms\n",
    "\n",
    "def save_test_results(experiment_name: str, \n",
    "                      model: torch.nn.Module, \n",
    "                      test_dataloader: torch.utils.data.DataLoader, \n",
    "                      device: str,\n",
    "                      save_dir: str = RESULTS_DIR):\n",
    "    \"\"\"\n",
    "    Orchestrates the testing process and saves all research-grade metrics.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    preds, labels, latency_ms = run_inference(model, test_dataloader, device)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    class_report = classification_report(labels, preds, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    ordinal_metrics = calculate_ordinal_metrics(preds, labels)\n",
    "    failure_indices = categorize_failures(preds, labels)\n",
    "    \n",
    "    final_metrics = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"global_accuracy\": acc,\n",
    "        \"inference_latency_ms\": latency_ms,\n",
    "        \"ordinal_metrics\": ordinal_metrics,\n",
    "        \"catastrophic_failure_counts\": {k: len(v) for k, v in failure_indices.items()},\n",
    "        \"classification_report\": class_report\n",
    "    }\n",
    "\n",
    "    json_path = f\"{save_dir}/{experiment_name}_metrics.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(final_metrics, f, indent=4)\n",
    "        \n",
    "    npy_path = f\"{save_dir}/{experiment_name}_confusion_matrix.npy\"\n",
    "    np.save(npy_path, conf_matrix)\n",
    "    \n",
    "    # Failure Indices JSON (for later visual analysis of specific FENs)\n",
    "    failures_path = f\"{save_dir}/{experiment_name}_failure_indices.json\"\n",
    "    with open(failures_path, \"w\") as f:\n",
    "        json.dump(failure_indices, f)\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"[Results] Accuracy:        {acc*100:.2f}%\")\n",
    "    print(f\"[Results] Off-by-1 Acc:    {ordinal_metrics['off_by_one_accuracy']*100:.2f}%\")\n",
    "    print(f\"[Results] MAE:             {ordinal_metrics['mae']:.4f}\")\n",
    "    print(f\"[Results] Latency:         {latency_ms:.4f} ms/sample\")\n",
    "    print(\"[Results] Catastrophic Failures (Count):\")\n",
    "    for k in sorted(failure_indices.keys()):\n",
    "        print(f\"   - Off by {k}: {len(failure_indices[k])} samples\")\n",
    "    print(f\"[Results] Saved all metrics to {save_dir}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed637bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"input_shape\": 775,\n",
    "    \"output_shape\": 7\n",
    "}\n",
    "\n",
    "dataset_paths = {\n",
    "    \"train\": str(TRAIN_PATH),\n",
    "    \"val\":   str(VAL_PATH),\n",
    "    \"test\":  str(TEST_PATH)\n",
    "}\n",
    "\n",
    "save_config_metadata(experiment_name=RUN_ID,\n",
    "                     model=model,\n",
    "                     hyperparams=hyperparams,\n",
    "                     dataset_paths=dataset_paths)\n",
    "\n",
    "# Save Training Logs (Using the 'result' variable from run_experiment)\n",
    "save_training_logs(experiment_name=RUN_ID, \n",
    "                   results_dict=result)\n",
    "\n",
    "save_test_results(experiment_name=RUN_ID,\n",
    "                  model=model,\n",
    "                  test_dataloader=test_dataloader,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = Path(f\"./experiments/logs/{model_save_name}/{RUN_ID}_learning_curves.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Val Loss', color='orange')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df['epoch'], df['train_acc'], label='Train Accuracy', color='blue')\n",
    "plt.plot(df['epoch'], df['val_acc'], label='Val Accuracy', color='orange')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5707c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessenv",
   "language": "python",
   "name": "chessenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
