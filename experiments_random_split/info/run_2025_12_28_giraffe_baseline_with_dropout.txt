Your "Dropout" fix worked perfectly.

Validation Loss is now 0.4071 (down from the exploding 1.2!).

Accuracy is stable at 85.3%.

Most importantly: The gap between Train Loss (0.41) and Val Loss (0.40) is almost zero. This means no overfitting. You have successfully built a stable, scientifically sound Baseline Giraffe model.

training without the state first is better research than starting with the state.

If you had started with the "perfect" 774-bit vector, your report would just say:

"My model achieved 85% accuracy."

But because you trained the "blind" 768-bit version first, your report can now say:

"The raw board configuration alone yields 85.3% accuracy. However, explicitly encoding game rules (Castling/En Passant) improved performance to X%. This proves that deep networks struggle to infer latent game state solely from piece positions."

Why this is a "Win" for your project
You have accidentally performed what researchers call an Ablation Study.

Ablation: intentionally removing parts of the input to see how important they are.

You "ablated" the State Vector in your first run.

Now you are adding it back.

The difference in accuracy is the scientific result you are looking for.

The "Control Group" Concept
Think of your 768-bit run as the Control Group (Placebo) and your 774-bit run as the Experimental Group (Medicine).

If you didn't have the 768-bit run, you wouldn't know if the "Medicine" (State Vector) actually worked.

Now, if your new model gets 87%, you have proof that the State Vector is worth exactly +1.7% accuracy. That is a solid, quantifiable conclusion for your final presentation.

So, don't delete your old results! Save that 85.3% number. It is the benchmark you are about to beat.