"""
    Improved DeepChess Architecture.
    Changes from V1:
    1. Added BatchNorm1d: Crucial for training deep nets without pretraining.
    2. Wider Bottleneck (100 -> 256): Gives the model more room to separate the 7 classes.
    3. Dropout in Encoder: Prevents the feature extractor from memorizing specific boards.
    added weight decay
    Important Training Adjustments
Since you are overfitting so heavily, you must update your optimizer to include Weight Decay. This forces the model to keep weights small and simple.

In your training loop cell, change the optimizer line to:

Python

# Added weight_decay=1e-4 for regularization
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
"""