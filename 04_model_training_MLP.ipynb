{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b389472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import chess\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ed291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.9\n",
      "GPU: NVIDIA GeForce RTX 3070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU:\", torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34890261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nv1 - 775-1024-600-400-200-100\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "v1 - 775-1024-600-400-200-100\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff0e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"run_2026_01_19_probs_mlp_v1\"\n",
    "model_save_name = \"probs_mlp_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39910bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, root_dir: Path, split: str, sigma: float = 0.6):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.split = split\n",
    "        self.sigma = sigma\n",
    "        self.num_classes = 7\n",
    "        self.class_indices = torch.arange(self.num_classes, dtype=torch.float32)\n",
    "        self.X = np.load(self.root_dir / f\"{self.split}_X.npy\", mmap_mode='r')\n",
    "        self.y = np.load(self.root_dir / f\"{self.split}_y.npy\", mmap_mode='r')\n",
    "        self.scores = np.load(self.root_dir / f\"{self.split}_scores.npy\", mmap_mode='r')\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def score_to_continuous_index(self, score: float) -> float:\n",
    "        \"\"\"\n",
    "        Maps Centipawn score to a continuous index (e.g. 400cp -> 1.5).\n",
    "        \"\"\"\n",
    "        \n",
    "        if score >= 500: \n",
    "            # Fade from 0.5 (at 500) to 0.0 (at 700)\n",
    "            return max(0.0, 0.5 - (score - 500) / 200.0)\n",
    "        \n",
    "        if score <= -500:\n",
    "            # Fade from 5.5 (at -500) to 6.0 (at -700)\n",
    "            return min(6.0, 5.5 + (-500 - score) / 200.0)\n",
    "        \n",
    "        # Interpolate the Middle Classes\n",
    "        # 300 to 500  -> Maps to 1.5 to 0.5\n",
    "        if score >= 300: return 1.5 - (score - 300) / 200.0\n",
    "        # 100 to 300  -> Maps to 2.5 to 1.5\n",
    "        if score >= 100: return 2.5 - (score - 100) / 200.0\n",
    "        # -100 to 100 -> Maps to 3.5 to 2.5\n",
    "        if score >= -100: return 3.5 - (score - (-100)) / 200.0\n",
    "        # -300 to -100 -> Maps to 4.5 to 3.5\n",
    "        if score >= -300: return 4.5 - (score - (-300)) / 200.0\n",
    "        # -500 to -300 -> Maps to 5.5 to 4.5\n",
    "        if score > -500: return 5.5 - (score - (-500)) / 200.0\n",
    "        \n",
    "        return 3.0 \n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        score = self.scores[idx].item()\n",
    "        target_idx = self.score_to_continuous_index(score)\n",
    "        \n",
    "        # Create Gaussian Distribution centered at target_idx\n",
    "        dist = torch.exp(-((self.class_indices - target_idx) ** 2) / (2 * self.sigma ** 2))\n",
    "        \n",
    "        # Normalize so it sums to 1.0\n",
    "        soft_target = dist / dist.sum()\n",
    "        \n",
    "        x_tensor = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "\n",
    "        # return self.X[idx], self.y[idx]\n",
    "        return x_tensor, soft_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15af8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "num_workers = 0 \n",
    "ROOT_DIR = Path(\"./dataset_bitmaps_cp/\")\n",
    "\n",
    "train_dataset = ChessDataset(root_dir=ROOT_DIR, split=\"train\")\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "val_dataset = ChessDataset(root_dir=ROOT_DIR, split=\"val\")\n",
    "val_dataloader = DataLoader(dataset=val_dataset, \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            num_workers=num_workers,\n",
    "                            shuffle=False,\n",
    "                            pin_memory=True)\n",
    "\n",
    "test_dataset = ChessDataset(root_dir=ROOT_DIR, split=\"test\")\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             num_workers=num_workers,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1afc6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg batch load time: 0.03596267938613892\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for i, (X, y) in enumerate(train_dataloader):\n",
    "    if i == 100:  # measure 100 batches\n",
    "        break\n",
    "print(\"Avg batch load time:\", (time.time() - start) / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5bdf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch shape: torch.Size([512, 775]) dtype: torch.float32\n",
      "y batch shape: torch.Size([512, 7]) dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "Xb, yb = next(iter(train_dataloader))\n",
    "print(\"X batch shape:\", Xb.shape, \"dtype:\", Xb.dtype)\n",
    "print(\"y batch shape:\", yb.shape, \"dtype:\", yb.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012618bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionLabel(Enum):\n",
    "    WHITE_WINNING = 0\n",
    "    WHITE_DECISIVE = 1\n",
    "    WHITE_BETTER = 2\n",
    "    EQUAL = 3\n",
    "    BLACK_BETTER = 4\n",
    "    BLACK_DECISIVE = 5\n",
    "    BLACK_WINNING = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6db7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_shape=775, output_shape=7):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_shape, 1024), \n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(1024, 600),\n",
    "            nn.BatchNorm1d(600),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(600, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(400, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(128, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a409f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               scaler: torch.amp.GradScaler,\n",
    "               device=device) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Performs one training epoch for the given model.\n",
    "    Returns the average loss and accuracy across all batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device) # X and Y are both shape (BATCH_SIZE,)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        with torch.amp.autocast(device):\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Update weights\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()  \n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy metrics\n",
    "        \"\"\"softmax and argmax dim=1 because tensor of shape (batchsize, num_classes)\"\"\"\n",
    "        y_pred_class = torch.argmax(y_pred, dim=-1) # y_pred_class.shape = (BATCH_SIZE,)\n",
    "        # train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "        # Remove for non prob ablation\n",
    "        y_true_class = torch.argmax(y, dim=-1)\n",
    "        train_acc += (y_pred_class == y_true_class).sum().item()/len(y_pred)\n",
    "        \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56112dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device=device) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the given model on the given dataloader without gradient updates.\n",
    "    Dataloader should either be the validation or test dataloader.\n",
    "    Returns the average loss and accuracy across all batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy metrics\n",
    "            test_pred_labels = torch.argmax(test_pred, dim=1)\n",
    "            # test_acc += (test_pred_labels == y).sum().item()/len(test_pred_labels)\n",
    "\n",
    "            # Remove for non prob ablation\n",
    "            y_true_labels = torch.argmax(y, dim=1)\n",
    "            test_acc += (test_pred_labels == y_true_labels).sum().item()/len(test_pred_labels)\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121015af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "def run_experiment(model: torch.nn.Module,\n",
    "                   model_save_name: str,\n",
    "                   train_dataloader: torch.utils.data.DataLoader,\n",
    "                   val_dataloader: torch.utils.data.DataLoader,\n",
    "                   loss_fn: torch.nn.Module,\n",
    "                   optimizer: torch.optim.Optimizer,\n",
    "                   scaler: torch.amp.GradScaler,\n",
    "                   epochs: int,\n",
    "                   patience: int,\n",
    "                   device=device):\n",
    "    \n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"val_acc\": []}\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0 \n",
    "    \n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer, mode='min', factor=0.1, patience=3\n",
    "    # )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=epochs,      \n",
    "        eta_min=1e-6         \n",
    "    )\n",
    "    \n",
    "    print(f\"Starting Training: {model_save_name}\")\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device,\n",
    "                                           scaler=scaler)\n",
    "        val_loss, val_acc = eval_step(model=model,\n",
    "                                      dataloader=val_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device)\n",
    "        \n",
    "        # scheduler.step(val_loss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_acc > best_val_acc: \n",
    "            best_val_acc = val_acc\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "            \n",
    "            print(f\"Epoch: {epoch} | New Best Val Acc: {val_acc:.4f} (Saved)\")\n",
    "            torch.save(model.state_dict(), f\"models/{model_save_name}.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Epoch: No improvement. Patience {patience_counter}/{patience}\")\n",
    "\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n[Early Stopping] No improvement for {patience} epochs. Stopping.\")\n",
    "            break \n",
    "\n",
    "    if best_model_weights is not None:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "        print(f\"\\nLoaded best model weights with Val Acc: {best_val_acc:.4f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34e1f957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MLP                                      [512, 7]                  --\n",
       "├─Sequential: 1-1                        [512, 7]                  --\n",
       "│    └─Linear: 2-1                       [512, 1024]               794,624\n",
       "│    └─BatchNorm1d: 2-2                  [512, 1024]               2,048\n",
       "│    └─ReLU: 2-3                         [512, 1024]               --\n",
       "│    └─Dropout: 2-4                      [512, 1024]               --\n",
       "│    └─Linear: 2-5                       [512, 600]                615,000\n",
       "│    └─BatchNorm1d: 2-6                  [512, 600]                1,200\n",
       "│    └─ReLU: 2-7                         [512, 600]                --\n",
       "│    └─Dropout: 2-8                      [512, 600]                --\n",
       "│    └─Linear: 2-9                       [512, 400]                240,400\n",
       "│    └─BatchNorm1d: 2-10                 [512, 400]                800\n",
       "│    └─ReLU: 2-11                        [512, 400]                --\n",
       "│    └─Dropout: 2-12                     [512, 400]                --\n",
       "│    └─Linear: 2-13                      [512, 256]                102,656\n",
       "│    └─BatchNorm1d: 2-14                 [512, 256]                512\n",
       "│    └─ReLU: 2-15                        [512, 256]                --\n",
       "│    └─Dropout: 2-16                     [512, 256]                --\n",
       "│    └─Linear: 2-17                      [512, 128]                32,896\n",
       "│    └─BatchNorm1d: 2-18                 [512, 128]                256\n",
       "│    └─ReLU: 2-19                        [512, 128]                --\n",
       "│    └─Dropout: 2-20                     [512, 128]                --\n",
       "│    └─Linear: 2-21                      [512, 7]                  903\n",
       "==========================================================================================\n",
       "Total params: 1,791,295\n",
       "Trainable params: 1,791,295\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 917.14\n",
       "==========================================================================================\n",
       "Input size (MB): 1.59\n",
       "Forward/backward pass size (MB): 19.76\n",
       "Params size (MB): 7.17\n",
       "Estimated Total Size (MB): 28.51\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = MLP(input_shape=775, \n",
    "            output_shape=7).to(device)\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE,775))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be43b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training: probs_mlp_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [06:08<10:07:37, 368.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | New Best Val Acc: 0.4803 (Saved)\n",
      "Epoch: 0 | Train Loss: 1.4833 | Val Loss: 1.4093 | Val Acc: 0.4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [12:20<10:05:28, 370.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | New Best Val Acc: 0.5092 (Saved)\n",
      "Epoch: 1 | Train Loss: 1.3955 | Val Loss: 1.3664 | Val Acc: 0.5092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [18:32<9:59:50, 371.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | New Best Val Acc: 0.5237 (Saved)\n",
      "Epoch: 2 | Train Loss: 1.3596 | Val Loss: 1.3467 | Val Acc: 0.5237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [24:47<9:56:10, 372.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | New Best Val Acc: 0.5304 (Saved)\n",
      "Epoch: 3 | Train Loss: 1.3381 | Val Loss: 1.3336 | Val Acc: 0.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [30:54<9:46:44, 370.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | New Best Val Acc: 0.5365 (Saved)\n",
      "Epoch: 4 | Train Loss: 1.3236 | Val Loss: 1.3268 | Val Acc: 0.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [37:03<9:39:56, 370.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | New Best Val Acc: 0.5395 (Saved)\n",
      "Epoch: 5 | Train Loss: 1.3130 | Val Loss: 1.3231 | Val Acc: 0.5395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [43:14<9:34:13, 370.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | New Best Val Acc: 0.5447 (Saved)\n",
      "Epoch: 6 | Train Loss: 1.3046 | Val Loss: 1.3165 | Val Acc: 0.5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [49:25<9:28:03, 370.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | New Best Val Acc: 0.5456 (Saved)\n",
      "Epoch: 7 | Train Loss: 1.2980 | Val Loss: 1.3131 | Val Acc: 0.5456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [55:36<9:22:08, 370.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | New Best Val Acc: 0.5509 (Saved)\n",
      "Epoch: 8 | Train Loss: 1.2927 | Val Loss: 1.3070 | Val Acc: 0.5509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [1:01:47<9:16:17, 370.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | New Best Val Acc: 0.5532 (Saved)\n",
      "Epoch: 9 | Train Loss: 1.2877 | Val Loss: 1.3033 | Val Acc: 0.5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [1:07:59<9:10:36, 371.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | New Best Val Acc: 0.5544 (Saved)\n",
      "Epoch: 10 | Train Loss: 1.2838 | Val Loss: 1.3016 | Val Acc: 0.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [1:14:14<9:06:08, 372.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | New Best Val Acc: 0.5549 (Saved)\n",
      "Epoch: 11 | Train Loss: 1.2802 | Val Loss: 1.3012 | Val Acc: 0.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [1:20:26<8:59:51, 372.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | New Best Val Acc: 0.5559 (Saved)\n",
      "Epoch: 12 | Train Loss: 1.2770 | Val Loss: 1.2981 | Val Acc: 0.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [1:26:39<8:53:43, 372.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | New Best Val Acc: 0.5568 (Saved)\n",
      "Epoch: 13 | Train Loss: 1.2744 | Val Loss: 1.2977 | Val Acc: 0.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [1:32:51<8:47:20, 372.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | New Best Val Acc: 0.5579 (Saved)\n",
      "Epoch: 14 | Train Loss: 1.2716 | Val Loss: 1.2963 | Val Acc: 0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [1:39:05<8:41:54, 372.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | New Best Val Acc: 0.5612 (Saved)\n",
      "Epoch: 15 | Train Loss: 1.2697 | Val Loss: 1.2923 | Val Acc: 0.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [1:45:17<8:35:32, 372.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | New Best Val Acc: 0.5620 (Saved)\n",
      "Epoch: 16 | Train Loss: 1.2674 | Val Loss: 1.2895 | Val Acc: 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [1:51:31<8:29:54, 373.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 17 | Train Loss: 1.2652 | Val Loss: 1.2897 | Val Acc: 0.5611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [1:57:45<8:24:08, 373.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | New Best Val Acc: 0.5625 (Saved)\n",
      "Epoch: 18 | Train Loss: 1.2634 | Val Loss: 1.2882 | Val Acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [2:03:51<8:14:36, 370.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | New Best Val Acc: 0.5641 (Saved)\n",
      "Epoch: 19 | Train Loss: 1.2617 | Val Loss: 1.2868 | Val Acc: 0.5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [2:10:12<8:12:37, 374.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 20 | Train Loss: 1.2600 | Val Loss: 1.2885 | Val Acc: 0.5636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [2:16:24<8:05:23, 373.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | New Best Val Acc: 0.5658 (Saved)\n",
      "Epoch: 21 | Train Loss: 1.2580 | Val Loss: 1.2844 | Val Acc: 0.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [2:22:40<8:00:19, 374.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | New Best Val Acc: 0.5659 (Saved)\n",
      "Epoch: 22 | Train Loss: 1.2568 | Val Loss: 1.2840 | Val Acc: 0.5659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [2:28:57<7:55:03, 375.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 23 | Train Loss: 1.2551 | Val Loss: 1.2828 | Val Acc: 0.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [2:35:10<7:47:54, 374.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | New Best Val Acc: 0.5669 (Saved)\n",
      "Epoch: 24 | Train Loss: 1.2536 | Val Loss: 1.2813 | Val Acc: 0.5669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [2:41:30<7:44:00, 376.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | New Best Val Acc: 0.5690 (Saved)\n",
      "Epoch: 25 | Train Loss: 1.2524 | Val Loss: 1.2801 | Val Acc: 0.5690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [2:47:51<7:39:25, 377.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | New Best Val Acc: 0.5693 (Saved)\n",
      "Epoch: 26 | Train Loss: 1.2508 | Val Loss: 1.2790 | Val Acc: 0.5693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [2:53:56<7:28:27, 373.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 27 | Train Loss: 1.2496 | Val Loss: 1.2813 | Val Acc: 0.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [2:59:36<7:10:33, 363.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 28 | Train Loss: 1.2481 | Val Loss: 1.2790 | Val Acc: 0.5693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [3:05:54<7:09:06, 367.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | New Best Val Acc: 0.5706 (Saved)\n",
      "Epoch: 29 | Train Loss: 1.2466 | Val Loss: 1.2767 | Val Acc: 0.5706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [3:12:09<7:05:47, 370.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | New Best Val Acc: 0.5718 (Saved)\n",
      "Epoch: 30 | Train Loss: 1.2453 | Val Loss: 1.2765 | Val Acc: 0.5718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [3:18:24<7:00:58, 371.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | New Best Val Acc: 0.5723 (Saved)\n",
      "Epoch: 31 | Train Loss: 1.2440 | Val Loss: 1.2756 | Val Acc: 0.5723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [3:24:39<6:55:57, 372.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 32 | Train Loss: 1.2426 | Val Loss: 1.2751 | Val Acc: 0.5719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [3:30:53<6:50:21, 373.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | New Best Val Acc: 0.5738 (Saved)\n",
      "Epoch: 33 | Train Loss: 1.2414 | Val Loss: 1.2710 | Val Acc: 0.5738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [3:37:07<6:44:20, 373.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | New Best Val Acc: 0.5741 (Saved)\n",
      "Epoch: 34 | Train Loss: 1.2403 | Val Loss: 1.2718 | Val Acc: 0.5741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [3:43:21<6:38:24, 373.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 35 | Train Loss: 1.2388 | Val Loss: 1.2726 | Val Acc: 0.5737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [3:49:35<6:32:18, 373.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 36 | Train Loss: 1.2375 | Val Loss: 1.2725 | Val Acc: 0.5730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [3:55:38<6:23:00, 370.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | New Best Val Acc: 0.5753 (Saved)\n",
      "Epoch: 37 | Train Loss: 1.2361 | Val Loss: 1.2706 | Val Acc: 0.5753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [4:01:09<6:04:30, 358.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | New Best Val Acc: 0.5759 (Saved)\n",
      "Epoch: 38 | Train Loss: 1.2347 | Val Loss: 1.2687 | Val Acc: 0.5759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [4:07:18<6:01:46, 361.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 39 | Train Loss: 1.2333 | Val Loss: 1.2697 | Val Acc: 0.5752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [4:13:08<5:52:15, 358.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 40 | Train Loss: 1.2324 | Val Loss: 1.2706 | Val Acc: 0.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [4:18:50<5:41:26, 353.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | New Best Val Acc: 0.5783 (Saved)\n",
      "Epoch: 41 | Train Loss: 1.2310 | Val Loss: 1.2677 | Val Acc: 0.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [4:24:26<5:30:51, 348.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 42 | Train Loss: 1.2297 | Val Loss: 1.2687 | Val Acc: 0.5776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [4:30:34<5:30:33, 354.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | New Best Val Acc: 0.5785 (Saved)\n",
      "Epoch: 43 | Train Loss: 1.2283 | Val Loss: 1.2654 | Val Acc: 0.5785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [4:36:00<5:16:45, 345.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 44 | Train Loss: 1.2272 | Val Loss: 1.2681 | Val Acc: 0.5767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [4:41:22<5:04:43, 338.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | New Best Val Acc: 0.5796 (Saved)\n",
      "Epoch: 45 | Train Loss: 1.2257 | Val Loss: 1.2657 | Val Acc: 0.5796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [4:47:19<5:04:01, 344.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 46 | Train Loss: 1.2243 | Val Loss: 1.2663 | Val Acc: 0.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [4:53:07<4:59:06, 345.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 | New Best Val Acc: 0.5804 (Saved)\n",
      "Epoch: 47 | Train Loss: 1.2228 | Val Loss: 1.2652 | Val Acc: 0.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [4:59:07<4:57:10, 349.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | New Best Val Acc: 0.5807 (Saved)\n",
      "Epoch: 48 | Train Loss: 1.2213 | Val Loss: 1.2642 | Val Acc: 0.5807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [5:05:02<4:52:51, 351.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 49 | Train Loss: 1.2201 | Val Loss: 1.2678 | Val Acc: 0.5788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [5:10:55<4:47:24, 351.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 50 | Train Loss: 1.2184 | Val Loss: 1.2637 | Val Acc: 0.5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [5:16:26<4:36:31, 345.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 | New Best Val Acc: 0.5814 (Saved)\n",
      "Epoch: 51 | Train Loss: 1.2167 | Val Loss: 1.2624 | Val Acc: 0.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [5:22:14<4:31:11, 346.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 52 | Train Loss: 1.2157 | Val Loss: 1.2634 | Val Acc: 0.5812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [5:28:24<4:30:50, 353.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 53 | Train Loss: 1.2139 | Val Loss: 1.2644 | Val Acc: 0.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [5:34:39<4:29:50, 359.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 54 | Train Loss: 1.2128 | Val Loss: 1.2645 | Val Acc: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [5:40:52<4:26:47, 363.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 | New Best Val Acc: 0.5830 (Saved)\n",
      "Epoch: 55 | Train Loss: 1.2108 | Val Loss: 1.2612 | Val Acc: 0.5830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [5:46:36<4:16:34, 358.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 | New Best Val Acc: 0.5838 (Saved)\n",
      "Epoch: 56 | Train Loss: 1.2094 | Val Loss: 1.2628 | Val Acc: 0.5838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [5:52:17<4:07:00, 352.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 | New Best Val Acc: 0.5846 (Saved)\n",
      "Epoch: 57 | Train Loss: 1.2082 | Val Loss: 1.2602 | Val Acc: 0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [5:57:54<3:57:54, 348.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 58 | Train Loss: 1.2063 | Val Loss: 1.2601 | Val Acc: 0.5839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [6:03:31<3:49:50, 344.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 59 | Train Loss: 1.2047 | Val Loss: 1.2606 | Val Acc: 0.5840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [6:09:22<3:45:11, 346.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | New Best Val Acc: 0.5855 (Saved)\n",
      "Epoch: 60 | Train Loss: 1.2033 | Val Loss: 1.2598 | Val Acc: 0.5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [6:15:18<3:41:23, 349.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 61 | Train Loss: 1.2012 | Val Loss: 1.2587 | Val Acc: 0.5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [6:21:15<3:36:51, 351.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 | New Best Val Acc: 0.5867 (Saved)\n",
      "Epoch: 62 | Train Loss: 1.1998 | Val Loss: 1.2576 | Val Acc: 0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [6:27:29<3:35:03, 358.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 63 | Train Loss: 1.1983 | Val Loss: 1.2601 | Val Acc: 0.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [6:33:43<3:31:42, 362.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 | New Best Val Acc: 0.5868 (Saved)\n",
      "Epoch: 64 | Train Loss: 1.1967 | Val Loss: 1.2569 | Val Acc: 0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [6:40:00<3:28:10, 367.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 65 | Train Loss: 1.1952 | Val Loss: 1.2588 | Val Acc: 0.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [6:46:16<3:23:26, 369.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 66 | Train Loss: 1.1933 | Val Loss: 1.2588 | Val Acc: 0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [6:52:27<3:17:28, 370.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 | New Best Val Acc: 0.5870 (Saved)\n",
      "Epoch: 67 | Train Loss: 1.1912 | Val Loss: 1.2586 | Val Acc: 0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [6:58:47<3:12:48, 373.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 | New Best Val Acc: 0.5870 (Saved)\n",
      "Epoch: 68 | Train Loss: 1.1897 | Val Loss: 1.2584 | Val Acc: 0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [7:05:01<3:06:39, 373.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 | New Best Val Acc: 0.5885 (Saved)\n",
      "Epoch: 69 | Train Loss: 1.1877 | Val Loss: 1.2567 | Val Acc: 0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [7:10:24<2:53:08, 358.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 1/101\n",
      "Epoch: 70 | Train Loss: 1.1862 | Val Loss: 1.2597 | Val Acc: 0.5869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [7:16:17<2:46:25, 356.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 2/101\n",
      "Epoch: 71 | Train Loss: 1.1844 | Val Loss: 1.2603 | Val Acc: 0.5864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [7:22:13<2:40:24, 356.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: No improvement. Patience 3/101\n",
      "Epoch: 72 | Train Loss: 1.1828 | Val Loss: 1.2591 | Val Acc: 0.5864\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(),\n",
    "                              lr=0.001,\n",
    "                              weight_decay=0.01)\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "result = run_experiment(model=model,\n",
    "                        model_save_name=model_save_name,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        scaler=scaler,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        patience=NUM_EPOCHS + 1,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23488d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_to_index = {\"P\":0,\n",
    "                  \"N\":1,\n",
    "                  \"B\":2,\n",
    "                  \"R\":3,\n",
    "                  \"Q\":4,\n",
    "                  \"K\":5,\n",
    "                  \"p\":6,\n",
    "                  \"n\":7,\n",
    "                  \"b\":8,\n",
    "                  \"r\":9,\n",
    "                  \"q\":10,\n",
    "                  \"k\":11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d13910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_vector(fen: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts FEN to a 775-dim vector (Bitboards + Game State).\n",
    "    \"\"\"\n",
    "    board = chess.Board(fen)\n",
    "    vector = np.zeros(775, dtype=np.uint8)\n",
    "    \n",
    "    for square, piece in board.piece_map().items():\n",
    "        idx = piece_to_index[piece.symbol()] * 64 + square\n",
    "        vector[idx] = 1\n",
    "\n",
    "    \n",
    "    # Side to Move (1 = White, 0 = Black)\n",
    "    vector[768] = 1.0 if board.turn == chess.WHITE else 0.0\n",
    "    \n",
    "    # Castling Rights\n",
    "    vector[769] = 1.0 if board.has_kingside_castling_rights(chess.WHITE) else 0.0\n",
    "    vector[770] = 1.0 if board.has_queenside_castling_rights(chess.WHITE) else 0.0\n",
    "    vector[771] = 1.0 if board.has_kingside_castling_rights(chess.BLACK) else 0.0\n",
    "    vector[772] = 1.0 if board.has_queenside_castling_rights(chess.BLACK) else 0.0\n",
    "    \n",
    "    # If there is an en-passant square target, set to 1\n",
    "    vector[773] = 1.0 if board.ep_square is not None else 0.0\n",
    "\n",
    "    # Is there a check?\n",
    "    vector[774] = 1.0 if board.is_check() else 0.0\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e936bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_prediction(model: torch.nn.Module,\n",
    "                           random_fen: str,\n",
    "                           fen_class: int,\n",
    "                           device=device):\n",
    "    \"\"\"Takes the given fen to see the board, predicted score and actual score\"\"\"\n",
    "\n",
    "    numpy_fen = fen_to_vector(random_fen)\n",
    "    torch_fen = torch.tensor(numpy_fen, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    pred = torch.argmax(model(torch_fen), dim=-1)\n",
    "    print(\"Model Prediction: \", pred.item())\n",
    "    print(\"Stockfish Evaluation: \", fen_class)\n",
    "\n",
    "# Remember to update fen_class manually\n",
    "random_fen = \"r3kb1r/p2b1pp1/2p1pq1p/P2n4/3P4/1Q3N2/1PP2PPP/R1B2RK1 b kq - 2 14\"\n",
    "check_model_prediction(model=model,\n",
    "                       random_fen=random_fen,\n",
    "                       fen_class=5, # remember to manually set \n",
    "                       device=device)\n",
    "\n",
    "board = chess.Board(random_fen)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in val_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X).argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        # all_labels.extend(y.cpu().numpy())\n",
    "        true_labels = y.argmax(dim=1) \n",
    "        all_labels.extend(true_labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efa820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "LOGS_DIR = f\"experiments/logs/{model_save_name}\"\n",
    "\n",
    "def save_config_metadata(experiment_name: str, \n",
    "                         model: torch.nn.Module, \n",
    "                         hyperparams: dict, \n",
    "                         dataset_paths: dict,\n",
    "                         save_dir: str = LOGS_DIR):\n",
    "    \"\"\"\n",
    "    Saves all 'static' setup details: Model architecture, parameter counts, \n",
    "    datasets used, and hyperparameters.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Model Metadata\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    config_data = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_architecture\": {\n",
    "            \"class_name\": model.__class__.__name__,\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"input_dim\": hyperparams.get(\"input_shape\", \"unknown\"),\n",
    "            \"output_dim\": hyperparams.get(\"output_shape\", \"unknown\"),\n",
    "            \"structure_summary\": str(model)\n",
    "        },\n",
    "        \"datasets\": dataset_paths,\n",
    "        \"hyperparameters\": hyperparams,\n",
    "        \"device\": torch.cuda.get_device_name() if torch.cuda.is_available() else \"cpu\"\n",
    "    }\n",
    "\n",
    "    file_path = f\"{save_dir}/{experiment_name}_config.json\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(config_data, f, indent=4)\n",
    "    \n",
    "    print(f\"[Config] Saved metadata to {file_path}\")\n",
    "    \n",
    "def save_training_logs(experiment_name: str, \n",
    "                       results_dict: dict, \n",
    "                       save_dir: str = LOGS_DIR):\n",
    "    \"\"\"\n",
    "    Saves the epoch-by-epoch learning curves (Loss/Acc) to CSV.\n",
    "    Expects results_dict to be the output from your run_experiment function.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df = pd.DataFrame(results_dict)\n",
    "    \n",
    "    if \"epoch\" not in df.columns:\n",
    "        df[\"epoch\"] = range(1, len(df) + 1)\n",
    "        \n",
    "    file_path = f\"{save_dir}/{experiment_name}_learning_curves.csv\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"[Logs] Saved training history to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "RESULTS_DIR = f\"experiments/results/{model_save_name}\"\n",
    "\n",
    "def calculate_ordinal_metrics(preds: np.ndarray,\n",
    "                              labels: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculates metrics specific to ordinal classification (where Class 0 is close to Class 1).\n",
    "    \"\"\"\n",
    "    abs_diffs = np.abs(preds - labels)\n",
    "    \n",
    "    metrics = {\n",
    "        \"mae\": float(np.mean(abs_diffs)),\n",
    "        \"off_by_one_accuracy\": float(np.mean(abs_diffs <= 1)),\n",
    "        \"off_by_two_accuracy\": float(np.mean(abs_diffs <= 2))\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def categorize_failures(preds: np.ndarray, \n",
    "                        labels: np.ndarray) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    Categorizes errors by magnitude.\n",
    "    Returns a dict where keys are the error magnitude (3, 4, 5, 6) and values are lists of dataset indices.\n",
    "    \"\"\"\n",
    "    abs_diffs = np.abs(preds - labels)\n",
    "    failure_dict = {}\n",
    "    \n",
    "    # We care about errors >= 3 (e.g. Predicting 'Equal' when 'Black Winning')\n",
    "    # Max error is 6 (Predicting 'White Winning' when 'Black Winning')\n",
    "    for magnitude in range(3, 7):\n",
    "        indices = np.where(abs_diffs == magnitude)[0].tolist()\n",
    "        if indices:\n",
    "            failure_dict[magnitude] = indices\n",
    "            \n",
    "    return failure_dict\n",
    "\n",
    "def run_inference(model: torch.nn.Module, \n",
    "                  dataloader: torch.utils.data.DataLoader, \n",
    "                  device: str) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Runs inference and tracks latency. Returns predictions, true labels, and avg latency per sample (ms).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            # all_labels.extend(y.cpu().numpy())\n",
    "            true_labels = y.argmax(dim=1) \n",
    "            all_labels.extend(true_labels.cpu().numpy())\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    num_samples = len(all_labels)\n",
    "    avg_latency_ms = (total_time / num_samples) * 1000\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), avg_latency_ms\n",
    "\n",
    "def save_test_results(experiment_name: str, \n",
    "                      model: torch.nn.Module, \n",
    "                      test_dataloader: torch.utils.data.DataLoader, \n",
    "                      device: str,\n",
    "                      save_dir: str = RESULTS_DIR):\n",
    "    \"\"\"\n",
    "    Orchestrates the testing process and saves all research-grade metrics.\n",
    "    \"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    preds, labels, latency_ms = run_inference(model, test_dataloader, device)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    class_report = classification_report(labels, preds, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    ordinal_metrics = calculate_ordinal_metrics(preds, labels)\n",
    "    failure_indices = categorize_failures(preds, labels)\n",
    "    \n",
    "    final_metrics = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"global_accuracy\": acc,\n",
    "        \"inference_latency_ms\": latency_ms,\n",
    "        \"ordinal_metrics\": ordinal_metrics,\n",
    "        \"catastrophic_failure_counts\": {k: len(v) for k, v in failure_indices.items()},\n",
    "        \"classification_report\": class_report\n",
    "    }\n",
    "\n",
    "    json_path = f\"{save_dir}/{experiment_name}_metrics.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(final_metrics, f, indent=4)\n",
    "        \n",
    "    npy_path = f\"{save_dir}/{experiment_name}_confusion_matrix.npy\"\n",
    "    np.save(npy_path, conf_matrix)\n",
    "    \n",
    "    # Failure Indices JSON (for later visual analysis of specific FENs)\n",
    "    failures_path = f\"{save_dir}/{experiment_name}_failure_indices.json\"\n",
    "    with open(failures_path, \"w\") as f:\n",
    "        json.dump(failure_indices, f)\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"[Results] Accuracy:        {acc*100:.2f}%\")\n",
    "    print(f\"[Results] Off-by-1 Acc:    {ordinal_metrics['off_by_one_accuracy']*100:.2f}%\")\n",
    "    print(f\"[Results] MAE:             {ordinal_metrics['mae']:.4f}\")\n",
    "    print(f\"[Results] Latency:         {latency_ms:.4f} ms/sample\")\n",
    "    print(\"[Results] Catastrophic Failures (Count):\")\n",
    "    for k in sorted(failure_indices.keys()):\n",
    "        print(f\"   - Off by {k}: {len(failure_indices[k])} samples\")\n",
    "    print(f\"[Results] Saved all metrics to {save_dir}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed637bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"input_shape\": 775,\n",
    "    \"output_shape\": 7\n",
    "}\n",
    "\n",
    "dataset_paths = {\n",
    "    \"train\": str(ROOT_DIR / \"train_X.npy\"),\n",
    "    \"val\":   str(ROOT_DIR / \"val_X.npy\"),\n",
    "    \"test\":  str(ROOT_DIR / \"test_X.npy\")\n",
    "}\n",
    "\n",
    "save_config_metadata(experiment_name=RUN_ID,\n",
    "                     model=model,\n",
    "                     hyperparams=hyperparams,\n",
    "                     dataset_paths=dataset_paths)\n",
    "\n",
    "# Save Training Logs (Using the 'result' variable from run_experiment)\n",
    "save_training_logs(experiment_name=RUN_ID, \n",
    "                   results_dict=result)\n",
    "\n",
    "save_test_results(experiment_name=RUN_ID,\n",
    "                  model=model,\n",
    "                  test_dataloader=test_dataloader,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = Path(f\"./experiments/logs/{model_save_name}/{RUN_ID}_learning_curves.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Val Loss', color='orange')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df['epoch'], df['train_acc'], label='Train Accuracy', color='blue')\n",
    "plt.plot(df['epoch'], df['val_acc'], label='Val Accuracy', color='orange')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e14216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessenv",
   "language": "python",
   "name": "chessenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
