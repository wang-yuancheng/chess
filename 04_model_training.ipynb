{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b389472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import chess\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ed291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.9\n",
      "GPU: NVIDIA GeForce RTX 3070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU:\", torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39910bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPZChessDataset(Dataset):\n",
    "    def __init__(self, npz_path: Path):\n",
    "        with np.load(npz_path) as data:\n",
    "            self.X = torch.tensor(data[\"X\"], dtype=torch.float32) # float32 for NNs\n",
    "            self.y = torch.tensor(data[\"y\"], dtype=torch.long) # long for CrossEntropyLoss\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15af8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "num_workers = 0\n",
    "\n",
    "train_dataloader = DataLoader(dataset=NPZChessDataset(\"./dataset_processed/chess_bitboard_train.npz\"), \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True)\n",
    "val_dataloader = DataLoader(dataset=NPZChessDataset(\"./dataset_processed/chess_bitboard_val.npz\"), \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            num_workers=num_workers,\n",
    "                            shuffle=False,\n",
    "                            pin_memory=True)\n",
    "test_dataloader = DataLoader(dataset=NPZChessDataset(\"./dataset_processed/chess_bitboard_test.npz\"), \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             num_workers=num_workers,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1afc6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg batch load time: 0.017298686504364013\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for i, (X, y) in enumerate(train_dataloader):\n",
    "    if i == 100:  # measure 100 batches\n",
    "        break\n",
    "print(\"Avg batch load time:\", (time.time() - start) / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d5bdf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch shape: torch.Size([2048, 768]) dtype: torch.float32\n",
      "y batch shape: torch.Size([2048]) dtype: torch.int64 classes in batch: [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "Xb, yb = next(iter(train_dataloader))\n",
    "print(\"X batch shape:\", Xb.shape, \"dtype:\", Xb.dtype)\n",
    "print(\"y batch shape:\", yb.shape, \"dtype:\", yb.dtype, \"classes in batch:\", yb.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012618bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionLabel(Enum):\n",
    "    WHITE_WINNING = 0\n",
    "    WHITE_DECISIVE = 1\n",
    "    WHITE_BETTER = 2\n",
    "    EQUAL = 3\n",
    "    BLACK_BETTER = 4\n",
    "    BLACK_DECISIVE = 5\n",
    "    BLACK_WINNING = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomTestModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = RandomTestModel(input_shape=768,\n",
    "                        hidden_units=100,\n",
    "                        output_shape=7) # 7 classes\n",
    "\n",
    "summary(model, input_size=(32, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device=device) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Performs one training epoch for the given model.\n",
    "    Returns the average loss and accuracy across all batches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device) # X and Y are both shape (BATCH_SIZE,)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy metrics\n",
    "        \"\"\"softmax and argmax dim=1 because tensor of shape (batchsize, num_classes)\"\"\"\n",
    "        y_pred_class = torch.argmax(y_pred, dim=-1) # y_pred_class.shape = (BATCH_SIZE,)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56112dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device=device) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the given model on the given dataloader without gradient updates.\n",
    "    Dataloader should either be the validation or test dataloader.\n",
    "    Returns the average loss and accuracy across all batches.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy metrics\n",
    "            test_pred_labels = torch.argmax(test_pred, dim=1)\n",
    "            test_acc += (test_pred_labels == y).sum().item()/len(test_pred_labels)\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121015af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def run_experiment(model: torch.nn.Module,\n",
    "                   train_dataloader: torch.utils.data.DataLoader,\n",
    "                   val_dataloader: torch.utils.data.DataLoader,\n",
    "                   loss_fn: torch.nn.Module,\n",
    "                   optimizer: torch.optim.Optimizer,\n",
    "                   epochs: int,\n",
    "                   device=device):\n",
    "    \n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"val_acc\": []}\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        \n",
    "        val_loss, val_acc = eval_step(model=model,\n",
    "                                      dataloader=val_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device)\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {train_loss} | Train Acc: {train_acc} | Val Loss: {val_loss} | Val Acc: {val_acc}\")\n",
    "\n",
    "        # To plot results later\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model = RandomTestModel(input_shape=768,\n",
    "                        hidden_units=100,\n",
    "                        output_shape=7).to(device) # 7 classes\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "result = run_experiment(model=model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23488d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_to_index = {\"P\":0,\n",
    "                  \"N\":1,\n",
    "                  \"B\":2,\n",
    "                  \"R\":3,\n",
    "                  \"Q\":4,\n",
    "                  \"K\":5,\n",
    "                  \"p\":6,\n",
    "                  \"n\":7,\n",
    "                  \"b\":8,\n",
    "                  \"r\":9,\n",
    "                  \"q\":10,\n",
    "                  \"k\":11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ca621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_vector(fen: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a FEN string into a 768-length binary vector.\n",
    "    Each of the 12 piece types has its own 64-slot block, one per square. \n",
    "    A 1 marks the presence of a piece on a square, 0 otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    board = chess.Board(fen)\n",
    "    vector = np.zeros(64*12, dtype=np.uint8)\n",
    "\n",
    "    for square, piece in board.piece_map().items():\n",
    "        idx = 64*piece_to_index[piece.symbol()] + square\n",
    "        vector[idx] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e936bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_prediction(model: torch.nn.Module,\n",
    "                           random_fen: str,\n",
    "                           fen_class: int,\n",
    "                           device=device):\n",
    "    \"\"\"Takes the given fen to see the board, predicted score and actual score\"\"\"\n",
    "\n",
    "    numpy_fen = fen_to_vector(random_fen)\n",
    "    torch_fen = torch.tensor(numpy_fen, dtype=torch.float32).to(device)\n",
    "    pred = torch.argmax(model(torch_fen), dim=-1)\n",
    "    print(\"Model Prediction: \", pred.item())\n",
    "    print(\"Stockfish Evaluation: \", fen_class)\n",
    "\n",
    "# Remember to update fen_class manually\n",
    "random_fen = \"3R4/2p2ppk/p1p2n1p/2P1p3/4P3/5P2/2q3PP/2B1R1K1 w - - 0 22\"\n",
    "check_model_prediction(model=model,\n",
    "                       random_fen=random_fen,\n",
    "                       fen_class=4,\n",
    "                       device=device) # white winning\n",
    "\n",
    "board = chess.Board(random_fen)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in val_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X).argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessenv",
   "language": "python",
   "name": "chessenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
